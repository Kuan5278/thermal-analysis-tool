# thermal_analysis_platform_v10.3.8_optimized_fixed.py
# æº«åº¦æ•¸æ“šè¦–è¦ºåŒ–å¹³å° - v10.3.8 å¤šæª”æ¡ˆç¨ç«‹åˆ†æ + Summaryæ•´åˆç‰ˆ (å„ªåŒ–ç‰ˆ + ä¿®å¾©ä¸€éµè¤‡è£½)

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import io
import re
from datetime import datetime, date, timedelta
import numpy as np
from abc import ABC, abstractmethod
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
import json
import os

# ç‰ˆæœ¬è³‡è¨Š
VERSION = "v10.3.8 Multi-File Analysis with Summary (Optimized + Fixed Copy with Borders)"
VERSION_DATE = "2025å¹´6æœˆ"

# =============================================================================
# 0. è¨ªå•è¨ˆæ•¸å™¨ (Visit Counter) - ä¿®å¾©ç‰ˆæœ¬
# =============================================================================

class VisitCounter:
    """è¨ªå•è¨ˆæ•¸å™¨ - ä¿®å¾©ç‰ˆæœ¬"""
    
    def __init__(self, counter_file="visit_counter.json"):
        self.counter_file = counter_file
        self.data = self._load_counter()
    
    def _load_counter(self) -> dict:
        """è¼‰å…¥è¨ˆæ•¸å™¨æ•¸æ“š"""
        try:
            if os.path.exists(self.counter_file):
                with open(self.counter_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                return {
                    "total_visits": 0,
                    "daily_visits": {},
                    "first_visit": None,
                    "last_visit": None
                }
        except Exception:
            return {
                "total_visits": 0,
                "daily_visits": {},
                "first_visit": None,
                "last_visit": None
            }
    
    def _save_counter(self):
        """ä¿å­˜è¨ˆæ•¸å™¨æ•¸æ“š"""
        try:
            with open(self.counter_file, 'w', encoding='utf-8') as f:
                json.dump(self.data, f, ensure_ascii=False, indent=2)
        except Exception:
            pass
    
    def increment_visit(self):
        """å¢åŠ è¨ªå•è¨ˆæ•¸"""
        now = datetime.now()
        today = now.strftime("%Y-%m-%d")
        
        # æ›´æ–°ç¸½è¨ªå•æ¬¡æ•¸
        self.data["total_visits"] += 1
        
        # æ›´æ–°ä»Šæ—¥è¨ªå•æ¬¡æ•¸
        if today not in self.data["daily_visits"]:
            self.data["daily_visits"][today] = 0
        self.data["daily_visits"][today] += 1
        
        # æ›´æ–°é¦–æ¬¡è¨ªå•æ™‚é–“
        if self.data["first_visit"] is None:
            self.data["first_visit"] = now.isoformat()
        
        # æ›´æ–°æœ€å¾Œè¨ªå•æ™‚é–“
        self.data["last_visit"] = now.isoformat()
        
        # æ¸…ç†èˆŠçš„æ—¥è¨ªå•è¨˜éŒ„ï¼ˆä¿ç•™æœ€è¿‘30å¤©ï¼‰
        self._cleanup_old_records()
        
        # ä¿å­˜æ•¸æ“š
        self._save_counter()
    
    def _cleanup_old_records(self):
        """æ¸…ç†30å¤©å‰çš„æ—¥è¨ªå•è¨˜éŒ„ - ä¿®å¾©ç‰ˆæœ¬"""
        try:
            today = date.today()
            # ä½¿ç”¨ timedelta æ­£ç¢ºè¨ˆç®—30å¤©å‰çš„æ—¥æœŸ
            cutoff_date = today - timedelta(days=30)
            cutoff_str = cutoff_date.strftime("%Y-%m-%d")
            
            # ç§»é™¤30å¤©å‰çš„è¨˜éŒ„
            keys_to_remove = [k for k in self.data["daily_visits"].keys() if k < cutoff_str]
            for key in keys_to_remove:
                del self.data["daily_visits"][key]
        except Exception:
            pass
    
    def get_stats(self) -> dict:
        """ç²å–çµ±è¨ˆä¿¡æ¯ - ä¿®å¾©ç‰ˆæœ¬"""
        today = date.today()
        today_str = today.strftime("%Y-%m-%d")
        
        # ä½¿ç”¨ timedelta æ­£ç¢ºè¨ˆç®—æ˜¨å¤©çš„æ—¥æœŸ
        yesterday = today - timedelta(days=1)
        yesterday_str = yesterday.strftime("%Y-%m-%d")
        
        # è¨ˆç®—æœ€è¿‘7å¤©è¨ªå•é‡ - ä½¿ç”¨ timedelta
        recent_7_days = 0
        for i in range(7):
            check_date = today - timedelta(days=i)
            check_date_str = check_date.strftime("%Y-%m-%d")
            recent_7_days += self.data["daily_visits"].get(check_date_str, 0)
        
        return {
            "total_visits": self.data["total_visits"],
            "today_visits": self.data["daily_visits"].get(today_str, 0),
            "yesterday_visits": self.data["daily_visits"].get(yesterday_str, 0),
            "recent_7_days": recent_7_days,
            "first_visit": self.data["first_visit"],
            "last_visit": self.data["last_visit"],
            "active_days": len(self.data["daily_visits"])
        }

def display_visit_counter():
    """é¡¯ç¤ºè¨ªå•è¨ˆæ•¸å™¨ - ä¿®å¾©ç‰ˆæœ¬"""
    # åˆå§‹åŒ–è¨ˆæ•¸å™¨
    if 'visit_counter' not in st.session_state:
        st.session_state.visit_counter = VisitCounter()
        st.session_state.visit_counted = False
    
    # åªåœ¨ç¬¬ä¸€æ¬¡åŠ è¼‰æ™‚è¨ˆæ•¸
    if not st.session_state.visit_counted:
        st.session_state.visit_counter.increment_visit()
        st.session_state.visit_counted = True
    
    # ç²å–çµ±è¨ˆæ•¸æ“š
    stats = st.session_state.visit_counter.get_stats()
    
    # é¡¯ç¤ºè¨ˆæ•¸å™¨
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ğŸ“Š ä½¿ç”¨çµ±è¨ˆ")
        
        # ä½¿ç”¨columnsä¾†ä¸¦æ’é¡¯ç¤º
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric(
                label="ğŸ’« ç¸½è¨ªå•",
                value=f"{stats['total_visits']:,}",
                help="è‡ªé¦–æ¬¡å•Ÿå‹•ä»¥ä¾†çš„ç¸½è¨ªå•æ¬¡æ•¸"
            )
            
            st.metric(
                label="ğŸ“… ä»Šæ—¥",
                value=f"{stats['today_visits']:,}",
                delta=f"+{stats['today_visits'] - stats['yesterday_visits']}" if stats['yesterday_visits'] > 0 else None,
                help="ä»Šæ—¥è¨ªå•æ¬¡æ•¸"
            )
        
        with col2:
            st.metric(
                label="ğŸ“ˆ è¿‘7å¤©",
                value=f"{stats['recent_7_days']:,}",
                help="æœ€è¿‘7å¤©ç¸½è¨ªå•æ¬¡æ•¸"
            )
            
            st.metric(
                label="ğŸ—“ï¸ æ´»èºå¤©æ•¸",
                value=f"{stats['active_days']:,}",
                help="æœ‰è¨ªå•è¨˜éŒ„çš„å¤©æ•¸"
            )
        
        # é¡¯ç¤ºè©³ç´°ä¿¡æ¯
        with st.expander("ğŸ“‹ è©³ç´°çµ±è¨ˆ", expanded=False):
            if stats['first_visit']:
                first_visit = datetime.fromisoformat(stats['first_visit'])
                st.write(f"ğŸš€ **é¦–æ¬¡ä½¿ç”¨ï¼š** {first_visit.strftime('%Y-%m-%d %H:%M')}")
            
            if stats['last_visit']:
                last_visit = datetime.fromisoformat(stats['last_visit'])
                st.write(f"â° **æœ€å¾Œä½¿ç”¨ï¼š** {last_visit.strftime('%Y-%m-%d %H:%M')}")
            
            st.write(f"ğŸ“Š **å¹³å‡æ¯æ—¥ï¼š** {stats['total_visits'] / max(stats['active_days'], 1):.1f} æ¬¡")
            
            # é¡¯ç¤ºæœ€è¿‘å¹¾å¤©çš„è¨ªå•è¶¨å‹¢ - ä½¿ç”¨ timedelta ä¿®å¾©ç‰ˆæœ¬
            recent_data = []
            today = date.today()
            for i in range(6, -1, -1):  # æœ€è¿‘7å¤©ï¼Œå€’åº
                check_date = today - timedelta(days=i)
                date_str = check_date.strftime("%Y-%m-%d")
                visits = st.session_state.visit_counter.data["daily_visits"].get(date_str, 0)
                recent_data.append({
                    'date': check_date.strftime("%m/%d"),
                    'visits': visits
                })
            
            if recent_data:
                st.write("ğŸ“ˆ **æœ€è¿‘7å¤©è¶¨å‹¢ï¼š**")
                trend_text = " | ".join([f"{d['date']}: {d['visits']}" for d in recent_data])
                st.code(trend_text, language=None)

# =============================================================================
# 1. æ•¸æ“šæ¨¡å‹å±¤ (Data Model Layer)
# =============================================================================

@dataclass
class LogMetadata:
    """Logæª”æ¡ˆå…ƒæ•¸æ“š"""
    filename: str
    log_type: str
    rows: int
    columns: int
    time_range: str
    file_size_kb: float

class LogData:
    """çµ±ä¸€çš„Logæ•¸æ“šæŠ½è±¡é¡"""
    def __init__(self, df: pd.DataFrame, metadata: LogMetadata):
        self.df = df
        self.metadata = metadata
        self._numeric_columns = None
    
    @property
    def numeric_columns(self) -> List[str]:
        """ç²å–æ•¸å€¼å‹æ¬„ä½"""
        if self._numeric_columns is None:
            self._numeric_columns = self.df.select_dtypes(include=['number']).columns.tolist()
        return self._numeric_columns
    
    def get_time_range(self) -> Tuple[float, float]:
        """ç²å–æ™‚é–“ç¯„åœï¼ˆç§’ï¼‰"""
        if self.df.empty:
            return (0.0, 0.0)
        return (0.0, self.df.index.total_seconds().max())
    
    def filter_by_time(self, x_limits: Tuple[float, float]):
        """æŒ‰æ™‚é–“ç¯„åœéæ¿¾æ•¸æ“š"""
        if x_limits is None:
            return self.df
        
        x_min_td = pd.to_timedelta(x_limits[0], unit='s')
        x_max_td = pd.to_timedelta(x_limits[1], unit='s')
        return self.df[(self.df.index >= x_min_td) & (self.df.index <= x_max_td)]

# =============================================================================
# 2. è§£æå™¨å±¤ (Parser Layer) - è¶…ç°¡æ½”ç‰ˆæœ¬
# =============================================================================

class ParseLogger:
    """è§£ææ—¥èªŒç®¡ç†å™¨ - çµ±ä¸€ç®¡ç†æ‰€æœ‰è§£æè¼¸å‡º"""
    
    def __init__(self):
        self.logs = []
        self.debug_logs = []
        self.success_logs = []
        self.error_logs = []
    
    def info(self, message: str):
        """è¨˜éŒ„ä¸€èˆ¬ä¿¡æ¯"""
        self.logs.append(f"â„¹ï¸ {message}")
    
    def debug(self, message: str):
        """è¨˜éŒ„èª¿è©¦ä¿¡æ¯"""
        self.debug_logs.append(f"ğŸ” {message}")
    
    def success(self, message: str):
        """è¨˜éŒ„æˆåŠŸä¿¡æ¯"""
        self.success_logs.append(f"âœ… {message}")
    
    def error(self, message: str):
        """è¨˜éŒ„éŒ¯èª¤ä¿¡æ¯"""
        self.error_logs.append(f"âŒ {message}")
    
    def warning(self, message: str):
        """è¨˜éŒ„è­¦å‘Šä¿¡æ¯"""
        self.logs.append(f"âš ï¸ {message}")
    
    def show_summary(self, filename: str, log_type: str):
        """é¡¯ç¤ºç°¡æ½”çš„è§£ææ‘˜è¦"""
        if self.success_logs:
            st.success(f"âœ… {log_type} è§£ææˆåŠŸï¼")
        elif self.error_logs:
            st.error(f"âŒ {filename} è§£æå¤±æ•—")
            return
    
    def show_detailed_logs(self, filename: str):
        """åœ¨æ‘ºç–Šå€åŸŸå…§é¡¯ç¤ºè©³ç´°æ—¥èªŒ"""
        with st.expander(f"ğŸ” è©³ç´°è§£ææ—¥èªŒ - {filename}", expanded=False):
            if self.debug_logs:
                st.markdown("**ğŸ” èª¿è©¦ä¿¡æ¯ï¼š**")
                for log in self.debug_logs:
                    st.code(log, language=None)
            
            if self.logs:
                st.markdown("**ğŸ“‹ è§£æéç¨‹ï¼š**")
                for log in self.logs:
                    st.write(log)
            
            if self.success_logs:
                st.markdown("**âœ… æˆåŠŸä¿¡æ¯ï¼š**")
                for log in self.success_logs:
                    st.write(log)
            
            if self.error_logs:
                st.markdown("**âŒ éŒ¯èª¤ä¿¡æ¯ï¼š**")
                for log in self.error_logs:
                    st.write(log)

class LogParser(ABC):
    """è§£æå™¨æŠ½è±¡åŸºé¡"""
    
    def __init__(self):
        self.logger = ParseLogger()
    
    @abstractmethod
    def can_parse(self, file_content: io.BytesIO, filename: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦èƒ½è§£ææ­¤æª”æ¡ˆ"""
        pass
    
    @abstractmethod
    def parse(self, file_content: io.BytesIO, filename: str) -> Optional[LogData]:
        """è§£ææª”æ¡ˆ"""
        pass
    
    @property
    @abstractmethod
    def log_type(self) -> str:
        """Logé¡å‹åç¨±"""
        pass

class GPUMonParser(LogParser):
    """GPUMonè§£æå™¨ - è¶…ç°¡æ½”ç‰ˆ"""
    
    @property
    def log_type(self) -> str:
        return "GPUMon Log"
    
    def can_parse(self, file_content: io.BytesIO, filename: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºGPUMonæ ¼å¼"""
        try:
            file_content.seek(0)
            first_content = ""
            for _ in range(100):
                try:
                    line = file_content.readline().decode('utf-8', errors='ignore')
                    if not line:
                        break
                    first_content += line
                except:
                    break
            
            indicators = [
                'GPU Informations' in first_content,
                'Iteration, Date, Timestamp' in first_content,
                'Temperature GPU (C)' in first_content,
                'iteration' in first_content.lower() and 'gpu' in first_content.lower(),
                'NVVDD' in first_content,
                'FBVDD' in first_content
            ]
            
            return any(indicators)
        except:
            return False
    
    def parse(self, file_content: io.BytesIO, filename: str) -> Optional[LogData]:
        """è§£æGPUMonæª”æ¡ˆ - éœé»˜ç‰ˆæœ¬"""
        try:
            file_content.seek(0)
            content = file_content.read().decode('utf-8', errors='ignore')
            lines = content.split('\n')
            
            self.logger.debug(f"æª”æ¡ˆç¸½è¡Œæ•¸: {len(lines)}")
            
            # å°‹æ‰¾æ¨™é¡Œè¡Œ
            header_row_index = self._find_header_row(lines)
            if header_row_index is None:
                self.logger.error("æ‰¾ä¸åˆ°æœ‰æ•ˆçš„æ¨™é¡Œè¡Œ")
                return None
            
            # è§£ææ•¸æ“š
            df = self._parse_data_rows(lines, header_row_index)
            if df is None:
                self.logger.error("æ•¸æ“šè¡Œè§£æå¤±æ•—")
                return None
            
            # è™•ç†æ™‚é–“
            df = self._process_time_data(df)
            if df is None:
                self.logger.error("æ™‚é–“æ•¸æ“šè™•ç†å¤±æ•—")
                return None
            
            # æ•¸å€¼è½‰æ›
            df = self._convert_numeric_columns(df)
            
            # æ·»åŠ å‰ç¶´ä¸¦è¨­ç½®ç´¢å¼•
            df = df.add_prefix('GPU: ')
            df.rename(columns={'GPU: time_index': 'time_index'}, inplace=True)
            result_df = df.set_index('time_index')
            
            # å‰µå»ºå…ƒæ•¸æ“š
            file_size_kb = len(content.encode('utf-8')) / 1024
            time_range = f"{result_df.index.min()} åˆ° {result_df.index.max()}"
            
            metadata = LogMetadata(
                filename=filename,
                log_type=self.log_type,
                rows=result_df.shape[0],
                columns=result_df.shape[1],
                time_range=time_range,
                file_size_kb=file_size_kb
            )
            
            self.logger.success(f"GPUMonè§£ææˆåŠŸï¼æ•¸æ“šå½¢ç‹€: {result_df.shape}")
            return LogData(result_df, metadata)
            
        except Exception as e:
            self.logger.error(f"GPUMonè§£æç•°å¸¸: {e}")
            return None
    
    def _find_header_row(self, lines: List[str]) -> Optional[int]:
        """éœé»˜å°‹æ‰¾æ¨™é¡Œè¡Œ"""
        for i, line in enumerate(lines):
            line_lower = line.lower()
            if ('iteration' in line_lower and 'date' in line_lower and 'timestamp' in line_lower):
                self.logger.debug(f"æ‰¾åˆ°æ¨™é¡Œè¡Œåœ¨ç¬¬ {i+1} è¡Œ")
                return i
        
        # å‚™ç”¨æœå°‹
        for i, line in enumerate(lines):
            if line.count(',') > 10 and ('iteration' in line.lower() or 'gpu' in line.lower()):
                self.logger.debug(f"å‚™ç”¨æ–¹å¼æ‰¾åˆ°æ¨™é¡Œè¡Œåœ¨ç¬¬ {i+1} è¡Œ")
                return i
        
        return None
    
    def _parse_data_rows(self, lines: List[str], header_row_index: int) -> Optional[pd.DataFrame]:
        """éœé»˜è§£ææ•¸æ“šè¡Œ"""
        header_line = lines[header_row_index]
        self.logger.debug(f"è§£ææ¨™é¡Œè¡Œï¼Œé•·åº¦: {len(header_line)}")
        
        headers = [h.strip() for h in header_line.split(',')]
        self.logger.debug(f"è§£æåˆ° {len(headers)} å€‹æ¬„ä½")
        
        data_rows = []
        valid_data_count = 0
        
        for i in range(header_row_index + 1, min(header_row_index + 100, len(lines))):
            line = lines[i].strip()
            if line and not line.startswith(','):
                try:
                    row_data = [cell.strip() for cell in line.split(',')]
                    if len(row_data) >= 3:
                        if (row_data[0].isdigit() or 
                            any(cell and cell != 'N/A' for cell in row_data[:5])):
                            data_rows.append(row_data)
                            valid_data_count += 1
                except Exception:
                    continue
        
        self.logger.debug(f"æ‰¾åˆ° {len(data_rows)} è¡Œæœ‰æ•ˆæ•¸æ“š")
        
        if not data_rows:
            return None
        
        # å‰µå»ºDataFrame
        max_cols = max(len(headers), max(len(row) for row in data_rows))
        
        while len(headers) < max_cols:
            headers.append(f'Column_{len(headers)}')
        
        for row in data_rows:
            while len(row) < max_cols:
                row.append('')
        
        df = pd.DataFrame(data_rows, columns=headers[:max_cols])
        self.logger.debug(f"DataFrameå‰µå»ºæˆåŠŸ: {df.shape}")
        
        return df
    
    def _process_time_data(self, df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """éœé»˜è™•ç†æ™‚é–“æ•¸æ“š"""
        try:
            if 'Date' in df.columns and 'Timestamp' in df.columns:
                self.logger.debug("è™•ç†æ™‚é–“æ ¼å¼: Date + Timestamp")
                
                df['Timestamp_fixed'] = df['Timestamp'].str.replace(r':(\d{3})$', r'.\1', regex=True)
                df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Timestamp_fixed'], errors='coerce')
                
            else:
                df['DateTime'] = pd.to_datetime('2025-01-01') + pd.to_timedelta(range(len(df)), unit='s')
            
            valid_datetime_count = df['DateTime'].notna().sum()
            self.logger.debug(f"æˆåŠŸè§£æçš„æ™‚é–“é»: {valid_datetime_count}/{len(df)}")
            
            if valid_datetime_count > 0:
                df['time_index'] = df['DateTime'] - df['DateTime'].iloc[0]
                valid_mask = df['time_index'].notna()
                df = df[valid_mask].copy()
                self.logger.debug(f"æ™‚é–“è§£ææˆåŠŸï¼Œæœ€çµ‚æ•¸æ“š: {len(df)} è¡Œ")
            else:
                df['time_index'] = pd.to_timedelta(range(len(df)), unit='s')
            
            return df
            
        except Exception as e:
            self.logger.warning(f"æ™‚é–“è§£æç•°å¸¸ï¼Œä½¿ç”¨é»˜èªæ™‚é–“: {e}")
            df['time_index'] = pd.to_timedelta(range(len(df)), unit='s')
            return df
    
    def _convert_numeric_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """éœé»˜è½‰æ›æ•¸å€¼å‹æ¬„ä½"""
        numeric_count = 0
        for col in df.columns:
            if col not in ['Date', 'Timestamp', 'DateTime', 'time_index', 'Iteration']:
                try:
                    df[col] = df[col].replace(['N/A', 'n/a', '', ' '], np.nan)
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    if not df[col].isna().all():
                        numeric_count += 1
                except:
                    pass
        
        self.logger.debug(f"è½‰æ›äº† {numeric_count} å€‹æ•¸å€¼æ¬„ä½")
        return df

class PTATParser(LogParser):
    """PTATè§£æå™¨ - è¶…ç°¡æ½”ç‰ˆ"""
    
    @property
    def log_type(self) -> str:
        return "PTAT Log"
    
    def can_parse(self, file_content: io.BytesIO, filename: str) -> bool:
        try:
            file_content.seek(0)
            first_content = file_content.read(2000).decode('utf-8', errors='ignore')
            return ('MSR Package Temperature' in first_content or 
                    'Version,Date,Time' in first_content)
        except:
            return False
    
    def parse(self, file_content: io.BytesIO, filename: str) -> Optional[LogData]:
        try:
            file_content.seek(0)
            df = pd.read_csv(file_content, header=0, thousands=',', low_memory=False)
            df.columns = df.columns.str.strip()
            
            if 'Time' not in df.columns:
                self.logger.error("æ‰¾ä¸åˆ°æ™‚é–“æ¬„ä½")
                return None
            
            time_series = df['Time'].astype(str).str.strip()
            time_series_cleaned = time_series.str.replace(r':(\d{3})$', r'.\1', regex=True)
            datetime_series = pd.to_datetime(time_series_cleaned, format='%H:%M:%S.%f', errors='coerce')
            
            valid_times_mask = datetime_series.notna()
            df = df[valid_times_mask].copy()
            
            if df.empty:
                self.logger.error("æ²’æœ‰æœ‰æ•ˆçš„æ™‚é–“æ•¸æ“š")
                return None
            
            valid_datetimes = datetime_series[valid_times_mask]
            df['time_index'] = valid_datetimes - valid_datetimes.iloc[0]
            df = df.add_prefix('PTAT: ')
            df.rename(columns={'PTAT: time_index': 'time_index'}, inplace=True)
            
            result_df = df.set_index('time_index')
            
            # å‰µå»ºå…ƒæ•¸æ“š
            file_size_kb = len(file_content.getvalue()) / 1024
            time_range = f"{result_df.index.min()} åˆ° {result_df.index.max()}"
            
            metadata = LogMetadata(
                filename=filename,
                log_type=self.log_type,
                rows=result_df.shape[0],
                columns=result_df.shape[1],
                time_range=time_range,
                file_size_kb=file_size_kb
            )
            
            self.logger.success(f"PTATè§£ææˆåŠŸï¼æ•¸æ“šå½¢ç‹€: {result_df.shape}")
            return LogData(result_df, metadata)
            
        except Exception as e:
            self.logger.error(f"PTATè§£æå¤±æ•—: {e}")
            return None

class YokogawaParser(LogParser):
    """YOKOGAWAè§£æå™¨ - v10.3.8 è¶…ç°¡æ½”ç‰ˆæœ¬"""
    
    @property
    def log_type(self) -> str:
        return "YOKOGAWA Log"
    
    def can_parse(self, file_content: io.BytesIO, filename: str) -> bool:
        # YOKOGAWAä½œç‚ºå…œåº•è§£æå™¨ï¼Œç¸½æ˜¯è¿”å›True
        return True
    
    def parse(self, file_content: io.BytesIO, filename: str) -> Optional[LogData]:
        self.logger.info(f"å•Ÿå‹•YOKOGAWAè§£æå™¨ (v10.3.8è¶…ç°¡æ½”ç‰ˆ) - {filename}")
        
        try:
            is_excel = '.xlsx' in filename.lower() or '.xls' in filename.lower()
            read_func = pd.read_excel if is_excel else pd.read_csv
            
            self.logger.debug(f"æª”æ¡ˆé¡å‹: {'Excel' if is_excel else 'CSV'}")
            
            # å‹•æ…‹æœç´¢å¯èƒ½çš„ header è¡Œ
            possible_headers = self._find_possible_headers(file_content, is_excel, read_func)
            
            df = None
            found_time_col = None
            successful_header = None
            
            self.logger.debug(f"å€™é¸headerè¡Œ: {possible_headers}")
            
            for header_row in possible_headers:
                try:
                    file_content.seek(0)
                    df = read_func(file_content, header=header_row, thousands=',')
                    df.columns = df.columns.str.strip()
                    
                    self.logger.debug(f"å˜—è©¦header_row={header_row}, å½¢ç‹€: {df.shape}")
                    
                    time_candidates = ['Time', 'TIME', 'time', 'Date', 'DATE', 'date', 
                                     'DateTime', 'DATETIME', 'datetime', 'æ™‚é–“', 'æ—¥æœŸæ™‚é–“',
                                     'Timestamp', 'TIMESTAMP', 'timestamp']
                    
                    for candidate in time_candidates:
                        if candidate in df.columns:
                            found_time_col = candidate
                            successful_header = header_row
                            self.logger.debug(f"æ‰¾åˆ°æ™‚é–“æ¬„ä½: {candidate}")
                            break
                    
                    if found_time_col:
                        break
                        
                except Exception as e:
                    self.logger.debug(f"header_row={header_row} å¤±æ•—: {e}")
                    continue
            
            if df is None or found_time_col is None:
                self.logger.error("ç„¡æ³•æ‰¾åˆ°æ™‚é–“æ¬„ä½")
                return None
            
            time_column = found_time_col
            self.logger.success(f"æˆåŠŸè§£æï¼Œheader_row={successful_header}, æ™‚é–“æ¬„ä½='{time_column}'")
            self.logger.debug(f"DataFrameå½¢ç‹€: {df.shape}")
            
            # å‹•æ…‹é‡å‘½åé‚è¼¯ - éœé»˜åŸ·è¡Œ
            if is_excel:
                try:
                    ch_row_idx, tag_row_idx = self._find_ch_tag_rows(file_content, successful_header)
                    
                    if ch_row_idx is not None and tag_row_idx is not None:
                        self.logger.debug(f"æ‰¾åˆ°CHè¡Œ(ç¬¬{ch_row_idx+1}è¡Œ)å’ŒTagè¡Œ(ç¬¬{tag_row_idx+1}è¡Œ)")
                        
                        # è®€å–CHè¡Œå’ŒTagè¡Œ
                        file_content.seek(0)
                        ch_row = pd.read_excel(file_content, header=None, skiprows=ch_row_idx, nrows=1).iloc[0]
                        file_content.seek(0)
                        tag_row = pd.read_excel(file_content, header=None, skiprows=tag_row_idx, nrows=1).iloc[0]
                        
                        # åŸ·è¡Œé‡å‘½å
                        df = self._perform_renaming(df, ch_row, tag_row)
                    else:
                        self.logger.info("æœªæ‰¾åˆ°CH/Tagè¡Œï¼Œä½¿ç”¨åŸå§‹æ¬„ä½åç¨±")
                        
                except Exception as e:
                    self.logger.warning(f"é‡å‘½åéç¨‹ç•°å¸¸: {e}")
            
            # è™•ç†æ™‚é–“å’Œå®Œæˆè§£æ
            result = self._process_time_and_finalize(df, time_column, file_content, filename)
            
            return result
            
        except Exception as e:
            self.logger.error(f"YOKOGAWAè§£æå™¨ç•°å¸¸: {e}")
            return None
    
    def _find_possible_headers(self, file_content: io.BytesIO, is_excel: bool, read_func) -> List[int]:
        """éœé»˜æœç´¢å¯èƒ½çš„headerè¡Œ"""
        if not is_excel:
            return [0, 1, 2]  # CSV é€šå¸¸åœ¨å‰å¹¾è¡Œ
        
        possible_headers = []
        
        self.logger.debug("é–‹å§‹æœç´¢headerè¡Œ...")
        
        # ç¬¬ä¸€éšæ®µï¼šé—œéµå­—æœç´¢
        time_keywords = ['time', 'date', 'timestamp', 'æ™‚é–“', 'æ—¥æœŸ']
        
        for pos in range(0, 50):  # æœç´¢å‰50è¡Œ
            try:
                file_content.seek(0)
                test_df = read_func(file_content, header=pos, nrows=1)
                columns_str = ' '.join(str(col).lower() for col in test_df.columns if pd.notna(col))
                
                # æª¢æŸ¥æ˜¯å¦åŒ…å«æ™‚é–“ç›¸é—œé—œéµè©
                if any(keyword in columns_str for keyword in time_keywords):
                    possible_headers.append(pos)
                    found_keywords = [kw for kw in time_keywords if kw in columns_str]
                    self.logger.debug(f"ç¬¬{pos+1}è¡ŒåŒ…å«æ™‚é–“é—œéµè©: {found_keywords}")
                    
            except Exception:
                continue
        
        # ç¬¬äºŒéšæ®µï¼šçµæ§‹æœç´¢
        if not possible_headers:
            self.logger.debug("é—œéµå­—æœç´¢å¤±æ•—ï¼Œä½¿ç”¨çµæ§‹æœç´¢")
            for pos in range(0, 50):
                try:
                    file_content.seek(0)
                    test_df = read_func(file_content, header=pos, nrows=1)
                    if test_df.shape[1] >= 5:  # è‡³å°‘è¦æœ‰5å€‹æ¬„ä½
                        possible_headers.append(pos)
                        if len(possible_headers) >= 10:  # æœ€å¤šæ‰¾10å€‹å€™é¸
                            break
                except Exception:
                    continue
        
        # ç¬¬ä¸‰éšæ®µï¼šé è¨­å€¼
        if not possible_headers:
            possible_headers = [29, 28, 30, 27, 26, 31, 32] if is_excel else [0, 1, 2]
            self.logger.debug("ä½¿ç”¨é è¨­æœç´¢ç¯„åœ")
        
        self.logger.debug(f"æ‰¾åˆ° {len(possible_headers)} å€‹å€™é¸headerè¡Œ")
        return possible_headers
    
    def _find_ch_tag_rows(self, file_content: io.BytesIO, header_row: int) -> Tuple[Optional[int], Optional[int]]:
        """éœé»˜å°‹æ‰¾CHè¡Œå’ŒTagè¡Œ"""
        ch_row_idx = None
        tag_row_idx = None
        
        self.logger.debug(f"åœ¨headerè¡Œ({header_row+1})é™„è¿‘æœç´¢CHå’ŒTagè¡Œ")
        
        # æœç´¢ç¯„åœ
        search_range = range(max(0, header_row - 8), header_row + 1)
        
        # åˆ†ææ‰€æœ‰å€™é¸è¡Œçš„å…§å®¹
        row_analysis = []
        for idx in search_range:
            try:
                file_content.seek(0)
                test_row = pd.read_excel(file_content, header=None, skiprows=idx, nrows=1).iloc[0]
                
                # åˆ†æé€™ä¸€è¡Œçš„å…§å®¹
                ch_count = 0
                meaningful_tags = []
                
                for val in test_row:
                    if pd.isna(val) or str(val).strip() == '':
                        continue
                    else:
                        val_str = str(val).strip()
                        
                        if val_str.upper().startswith('CH'):
                            ch_count += 1
                        elif self._is_meaningful_tag(val):
                            meaningful_tags.append(val_str)
                
                analysis = {
                    'row_idx': idx,
                    'ch_count': ch_count,
                    'meaningful_tags': meaningful_tags,
                    'meaningful_count': len(meaningful_tags)
                }
                row_analysis.append(analysis)
                
                self.logger.debug(f"ç¬¬{idx+1}è¡Œ: CH={ch_count}, ç”¨æˆ¶æ¨™ç±¤={len(meaningful_tags)}")
                
            except Exception as e:
                self.logger.debug(f"ç¬¬{idx+1}è¡Œåˆ†æå¤±æ•—: {e}")
                continue
        
        # å°‹æ‰¾CHè¡Œ
        for analysis in row_analysis:
            if analysis['ch_count'] >= 3:
                ch_row_idx = analysis['row_idx']
                self.logger.debug(f"æ‰¾åˆ°CHè¡Œåœ¨ç¬¬{ch_row_idx+1}è¡Œ")
                break
        
        # å°‹æ‰¾Tagè¡Œ
        if ch_row_idx is not None:
            tag_candidates = [a for a in row_analysis if a['row_idx'] != ch_row_idx and a['row_idx'] < header_row]
            
            best_tag_row = None
            max_tags = 0
            
            for candidate in tag_candidates:
                if candidate['meaningful_count'] > max_tags:
                    max_tags = candidate['meaningful_count']
                    best_tag_row = candidate
            
            if best_tag_row:
                tag_row_idx = best_tag_row['row_idx']
                self.logger.debug(f"æ‰¾åˆ°Tagè¡Œåœ¨ç¬¬{tag_row_idx+1}è¡Œ(å«{max_tags}å€‹ç”¨æˆ¶æ¨™ç±¤)")
        
        return ch_row_idx, tag_row_idx
    
    def _is_meaningful_tag(self, tag_val) -> bool:
        """åˆ¤æ–·Tagå€¼æ˜¯å¦æœ‰æ„ç¾©ï¼ˆç”¨æˆ¶è‡ªå®šç¾©ä»£è™Ÿï¼‰"""
        if pd.isna(tag_val):
            return False
            
        tag_str = str(tag_val).strip()
        
        # æ’é™¤ç©ºå€¼
        if tag_str in ['', 'nan', 'NaN', 'None']:
            return False
            
        # æ’é™¤å–®ç¨çš„ "Tag"
        if tag_str.upper() == 'TAG':
            return False
            
        # æ’é™¤ç³»çµ±æ¨™é¡Œè©
        system_titles = ['CHANNEL', 'CH', 'POINT', 'TEMP', 'SENSOR']
        if tag_str.upper() in system_titles:
            return False
            
        # å­—æ¯+æ•¸å­—çµ„åˆï¼Œå¾ˆå¯èƒ½æ˜¯ç”¨æˆ¶æ¨™ç±¤ï¼ˆå¦‚ U5, U19, L8ï¼‰
        if len(tag_str) <= 4 and any(c.isalpha() for c in tag_str) and any(c.isdigit() for c in tag_str):
            return True
            
        # åŒ…å«ä¸‹åŠƒç·šï¼Œå¾ˆå¯èƒ½æ˜¯ç”¨æˆ¶æ¨™ç±¤ï¼ˆå¦‚ CPU_Tcï¼‰
        if '_' in tag_str:
            return True
            
        # æ’é™¤çœ‹èµ·ä¾†åƒæ¸¬é‡æ•¸æ“šçš„æ•¸å­—
        try:
            float_val = float(tag_str)
            if (0 <= float_val <= 200 and '.' in tag_str and len(tag_str) > 4):
                return False
            elif len(tag_str) <= 3:
                return True
        except ValueError:
            pass
            
        # å…¶ä»–æƒ…æ³ï¼Œé•·åº¦å¤§æ–¼1å°±èªç‚ºæ˜¯æœ‰æ„ç¾©çš„
        if len(tag_str) >= 2:
            return True
            
        return False
    
    def _perform_renaming(self, df: pd.DataFrame, ch_row: pd.Series, tag_row: pd.Series) -> pd.DataFrame:
        """éœé»˜åŸ·è¡Œé‡å‘½åé‚è¼¯"""
        self.logger.debug("é–‹å§‹æ™ºèƒ½é‡å‘½åè™•ç†")
        
        # ä¿è­·é—œéµæ¬„ä½
        protected_columns = {
            'Date', 'TIME', 'Time', 'time', 'DATE', 'date',
            'DateTime', 'DATETIME', 'datetime', 
            'Timestamp', 'TIMESTAMP', 'timestamp',
            'sec', 'SEC', 'RT', 'rt', 'æ™‚é–“', 'æ—¥æœŸæ™‚é–“'
        }
        
        new_column_names = {}
        tag_used = 0
        ch_used = 0
        protected_count = 0
        original_kept = 0
        
        for i, original_col in enumerate(df.columns):
            # ä¿è­·é—œéµæ¬„ä½
            if original_col in protected_columns:
                final_name = original_col
                protected_count += 1
                new_column_names[original_col] = final_name
                continue
            
            # ç²å–Tagå€¼
            tag_name = ""
            if i < len(tag_row):
                tag_val = tag_row.iloc[i]
                if self._is_meaningful_tag(tag_val):
                    tag_name = str(tag_val).strip()
            
            # ç²å–CHå€¼
            ch_name = ""
            if i < len(ch_row):
                ch_val = ch_row.iloc[i]
                if pd.notna(ch_val) and str(ch_val).strip().upper().startswith('CH'):
                    ch_name = str(ch_val).strip()
            
            # æ±ºå®šæœ€çµ‚åç¨±
            if tag_name:
                final_name = tag_name
                tag_used += 1
            elif ch_name:
                final_name = ch_name
                ch_used += 1
            else:
                final_name = original_col
                original_kept += 1
            
            new_column_names[original_col] = final_name
        
        # åŸ·è¡Œé‡å‘½å
        df.rename(columns=new_column_names, inplace=True)
        
        self.logger.debug(f"é‡å‘½åå®Œæˆ: Tag={tag_used}, CH={ch_used}, ä¿è­·={protected_count}, åŸå={original_kept}")
        
        return df
    
    def _process_time_and_finalize(self, df: pd.DataFrame, time_column: str, file_content: io.BytesIO, filename: str) -> Optional[LogData]:
        """è™•ç†æ™‚é–“ä¸¦å®Œæˆè§£æ"""
        self.logger.debug("è™•ç†æ™‚é–“æ•¸æ“š")
        time_series = df[time_column].astype(str).str.strip()
        
        try:
            df['time_index'] = pd.to_timedelta(time_series + ':00').fillna(pd.to_timedelta('00:00:00'))
            if df['time_index'].isna().all():
                raise ValueError("Timedelta è½‰æ›å¤±æ•—")
            self.logger.debug("æ™‚é–“è§£ææˆåŠŸ (Timedeltaæ ¼å¼)")
        except:
            try:
                datetime_series = pd.to_datetime(time_series, format='%H:%M:%S', errors='coerce')
                if datetime_series.notna().sum() == 0:
                    datetime_series = pd.to_datetime(time_series, errors='coerce')
                df['time_index'] = datetime_series - datetime_series.iloc[0]
                self.logger.debug("æ™‚é–“è§£ææˆåŠŸ (DateTimeæ ¼å¼)")
            except Exception as e:
                self.logger.error(f"æ™‚é–“è§£æå¤±æ•—: {e}")
                return None
        
        valid_times_mask = df['time_index'].notna()
        if valid_times_mask.sum() == 0:
            self.logger.error("æ²’æœ‰æœ‰æ•ˆçš„æ™‚é–“æ•¸æ“š")
            return None
        
        df = df[valid_times_mask].copy()
        
        if len(df) > 0:
            start_time = df['time_index'].iloc[0]
            df['time_index'] = df['time_index'] - start_time
        
        # æ•¸å€¼è½‰æ›
        numeric_columns = df.select_dtypes(include=['number']).columns
        numeric_converted = len(numeric_columns)
        
        self.logger.debug(f"æ•¸å€¼è½‰æ›å®Œæˆï¼Œè™•ç†äº† {numeric_converted} å€‹æ¬„ä½")
        
        # æ·»åŠ å‰ç¶´
        df = df.add_prefix('YOKO: ')
        df.rename(columns={'YOKO: time_index': 'time_index'}, inplace=True)
        
        result_df = df.set_index('time_index')
        
        # å‰µå»ºå…ƒæ•¸æ“š
        file_size_kb = len(file_content.getvalue()) / 1024
        time_range = f"{result_df.index.min()} åˆ° {result_df.index.max()}"
        
        metadata = LogMetadata(
            filename=filename,
            log_type=self.log_type,
            rows=result_df.shape[0],
            columns=result_df.shape[1],
            time_range=time_range,
            file_size_kb=file_size_kb
        )
        
        self.logger.success(f"YOKOGAWA v10.3.8 è§£æå®Œæˆï¼æ•¸æ“šå½¢ç‹€: {result_df.shape}")
        
        return LogData(result_df, metadata)

# =============================================================================
# 3. è§£æå™¨è¨»å†Šç³»çµ± (Parser Registry) - è¶…ç°¡æ½”ç‰ˆ
# =============================================================================

class ParserRegistry:
    """è§£æå™¨è¨»å†Šç³»çµ± - è¶…ç°¡æ½”ç‰ˆ"""
    
    def __init__(self):
        self.parsers: List[LogParser] = []
    
    def register(self, parser: LogParser):
        """è¨»å†Šè§£æå™¨"""
        self.parsers.append(parser)
    
    def parse_file(self, uploaded_file) -> Optional[LogData]:
        """è§£ææª”æ¡ˆï¼Œè‡ªå‹•é¸æ“‡åˆé©çš„è§£æå™¨ - éœé»˜ç‰ˆæœ¬"""
        filename = uploaded_file.name
        file_content = io.BytesIO(uploaded_file.getvalue())
        is_excel = '.xlsx' in filename.lower() or '.xls' in filename.lower()
        
        # å‰µå»ºä¸€å€‹è‡¨æ™‚çš„æ—¥èªŒæ”¶é›†å™¨ä¾†é¡¯ç¤ºè§£ææ‘˜è¦
        parsing_summary = {"attempted": [], "successful": None, "failed": []}
        
        for parser in self.parsers:
            try:
                file_content.seek(0)
                parsing_summary["attempted"].append(parser.log_type)
                
                if parser.can_parse(file_content, filename):
                    file_content.seek(0)
                    result = parser.parse(file_content, filename)
                    if result is not None:
                        parsing_summary["successful"] = parser.log_type
                        # é¡¯ç¤ºè§£ææ‘˜è¦
                        parser.logger.show_summary(filename, parser.log_type)
                        # é¡¯ç¤ºè©³ç´°æ—¥èªŒï¼ˆæ‘ºç–Šï¼‰
                        parser.logger.show_detailed_logs(filename)
                        return result
                    else:
                        parsing_summary["failed"].append(parser.log_type)
            except Exception as e:
                parsing_summary["failed"].append(f"{parser.log_type} (ç•°å¸¸: {str(e)[:50]})")
                continue
        
        # å¦‚æœæ‰€æœ‰è§£æå™¨éƒ½å¤±æ•—
        st.error(f"âŒ ç„¡æ³•è§£ææª”æ¡ˆ {filename}")
        with st.expander(f"ğŸ” è§£æå¤±æ•—è©³æƒ… - {filename}", expanded=False):
            st.write(f"**å˜—è©¦çš„è§£æå™¨:** {', '.join(parsing_summary['attempted'])}")
            if parsing_summary["failed"]:
                st.write(f"**å¤±æ•—çš„è§£æå™¨:** {', '.join(parsing_summary['failed'])}")
            st.write("**å»ºè­°:** ç¢ºèªæª”æ¡ˆæ ¼å¼æ˜¯å¦æ­£ç¢ºï¼Œæˆ–è¯ç¹«æŠ€è¡“æ”¯æ´")
        
        return None

# =============================================================================
# 4. çµ±è¨ˆè¨ˆç®—å±¤ (Statistics Layer)
# =============================================================================

class StatisticsCalculator:
    """çµ±è¨ˆè¨ˆç®—å™¨"""
    
    @staticmethod
    def calculate_gpumon_stats(log_data: LogData, x_limits=None):
        """è¨ˆç®—GPUMonçµ±è¨ˆæ•¸æ“š"""
        df = log_data.filter_by_time(x_limits)
        if df.empty:
            return None, None, None, None
        
        # GPUæº«åº¦çµ±è¨ˆ
        temp_stats = []
        temp_cols = [col for col in df.columns if 'Temperature' in col and 'GPU' in col]
        
        for col in temp_cols:
            temp_data = pd.to_numeric(df[col], errors='coerce').dropna()
            if len(temp_data) > 0:
                temp_stats.append({
                    'Temperature Sensor': col.replace('GPU: ', ''),
                    'Max (Â°C)': f"{temp_data.max():.2f}",
                    'Min (Â°C)': f"{temp_data.min():.2f}",
                    'Avg (Â°C)': f"{temp_data.mean():.2f}"
                })
        
        temp_df = pd.DataFrame(temp_stats) if temp_stats else None
        
        # GPUåŠŸè€—çµ±è¨ˆ
        power_stats = []
        target_power_items = ['NVVDD', 'FBVDD', 'TGP']
        
        for target_item in target_power_items:
            matching_cols = [col for col in df.columns if target_item in col and ('Power' in col or 'TGP' in col)]
            
            for col in matching_cols:
                power_data = pd.to_numeric(df[col], errors='coerce').dropna()
                if len(power_data) > 0:
                    display_name = col.replace('GPU: ', '')
                    if 'NVVDD' in col:
                        display_name = 'NVVDD Power'
                    elif 'FBVDD' in col:
                        display_name = 'FBVDD Power'
                    elif 'TGP' in col:
                        display_name = 'TGP (W)'
                    
                    power_stats.append({
                        'Power Rail': display_name,
                        'Max (W)': f"{power_data.max():.2f}",
                        'Min (W)': f"{power_data.min():.2f}",
                        'Avg (W)': f"{power_data.mean():.2f}"
                    })
                    break
        
        power_df = pd.DataFrame(power_stats) if power_stats else None
        
        # GPUé »ç‡çµ±è¨ˆ
        freq_stats = []
        freq_cols = [col for col in df.columns if 'Clock' in col and any(x in col for x in ['GPC', 'Memory'])]
        
        for col in freq_cols:
            freq_data = pd.to_numeric(df[col], errors='coerce').dropna()
            if len(freq_data) > 0:
                freq_stats.append({
                    'Clock Domain': col.replace('GPU: ', ''),
                    'Max (MHz)': f"{freq_data.max():.0f}",
                    'Min (MHz)': f"{freq_data.min():.0f}",
                    'Avg (MHz)': f"{freq_data.mean():.0f}"
                })
        
        freq_df = pd.DataFrame(freq_stats) if freq_stats else None
        
        # GPUä½¿ç”¨ç‡çµ±è¨ˆ
        util_stats = []
        util_cols = [col for col in df.columns if 'Utilization' in col]
        
        for col in util_cols:
            util_data = pd.to_numeric(df[col], errors='coerce').dropna()
            if len(util_data) > 0:
                util_stats.append({
                    'Utilization Type': col.replace('GPU: ', ''),
                    'Max (%)': f"{util_data.max():.1f}",
                    'Min (%)': f"{util_data.min():.1f}",
                    'Avg (%)': f"{util_data.mean():.1f}"
                })
        
        util_df = pd.DataFrame(util_stats) if util_stats else None
        
        return temp_df, power_df, freq_df, util_df
    
    @staticmethod
    def calculate_ptat_stats(log_data: LogData, x_limits=None):
        """è¨ˆç®—PTATçµ±è¨ˆæ•¸æ“š"""
        df = log_data.filter_by_time(x_limits)
        if df.empty:
            return None, None, None
        
        # CPU Core Frequency çµ±è¨ˆ
        freq_stats = []
        freq_cols = [col for col in df.columns if 'frequency' in col.lower() and 'core' in col.lower()]
        
        lfm_value = "N/A"
        hfm_value = "N/A"
        
        for col in df.columns:
            if 'lfm' in col.lower():
                lfm_data = pd.to_numeric(df[col], errors='coerce').dropna()
                if len(lfm_data) > 0:
                    lfm_value = f"{lfm_data.iloc[0]:.0f} MHz"
            elif 'hfm' in col.lower():
                hfm_data = pd.to_numeric(df[col], errors='coerce').dropna()
                if len(hfm_data) > 0:
                    hfm_value = f"{hfm_data.iloc[0]:.0f} MHz"
        
        if lfm_value == "N/A" or hfm_value == "N/A":
            all_freq_data = []
            for col in freq_cols:
                freq_data = pd.to_numeric(df[col], errors='coerce').dropna()
                all_freq_data.extend(freq_data.tolist())
            
            if all_freq_data:
                if lfm_value == "N/A":
                    lfm_value = f"{min(all_freq_data):.0f} MHz (ä¼°ç®—)"
                if hfm_value == "N/A":
                    hfm_value = f"{max(all_freq_data):.0f} MHz (ä¼°ç®—)"
        
        for col in freq_cols:
            freq_data = pd.to_numeric(df[col], errors='coerce').dropna()
            if len(freq_data) > 0:
                freq_stats.append({
                    'Core': col.replace('PTAT: ', ''),
                    'Max (MHz)': f"{freq_data.max():.0f}",
                    'Min (MHz)': f"{freq_data.min():.0f}",
                    'Avg (MHz)': f"{freq_data.mean():.0f}"
                })
        
        if freq_stats:
            freq_stats.append({
                'Core': '--- åƒè€ƒå€¼ ---',
                'Max (MHz)': '',
                'Min (MHz)': '',
                'Avg (MHz)': ''
            })
            freq_stats.append({
                'Core': 'LFM (Low Freq Mode)',
                'Max (MHz)': lfm_value,
                'Min (MHz)': '',
                'Avg (MHz)': ''
            })
            freq_stats.append({
                'Core': 'HFM (High Freq Mode)',
                'Max (MHz)': hfm_value,
                'Min (MHz)': '',
                'Avg (MHz)': ''
            })
        
        freq_df = pd.DataFrame(freq_stats) if freq_stats else None
        
        # Package Power çµ±è¨ˆ
        power_stats = []
        target_power_items = [
            ('IA', 'IA Power'),
            ('GT', 'GT Power'), 
            ('Rest of package', 'Rest of Package Power'),
            ('Package', 'Package Power')
        ]
        
        for search_term, display_name in target_power_items:
            matching_cols = []
            for col in df.columns:
                col_lower = col.lower()
                search_lower = search_term.lower()
                
                if search_term == 'IA':
                    if 'ia' in col_lower and 'power' in col_lower and 'via' not in col_lower:
                        matching_cols.append(col)
                elif search_term == 'GT':
                    if 'gt' in col_lower and 'power' in col_lower and 'tgp' not in col_lower:
                        matching_cols.append(col)
                elif search_term == 'Rest of package':
                    if 'rest' in col_lower and 'package' in col_lower and 'power' in col_lower:
                        matching_cols.append(col)
                elif search_term == 'Package':
                    if 'package' in col_lower and 'power' in col_lower and 'rest' not in col_lower:
                        matching_cols.append(col)
            
            if matching_cols:
                col = matching_cols[0]
                power_data = pd.to_numeric(df[col], errors='coerce').dropna()
                if len(power_data) > 0:
                    power_stats.append({
                        'Power Type': display_name,
                        'Max (W)': f"{power_data.max():.2f}",
                        'Min (W)': f"{power_data.min():.2f}",
                        'Avg (W)': f"{power_data.mean():.2f}"
                    })
        
        power_df = pd.DataFrame(power_stats) if power_stats else None
        
        # MSR Package Temperature çµ±è¨ˆ
        temp_stats = []
        temp_cols = [col for col in df.columns if 'temperature' in col.lower() and 'package' in col.lower() and 'msr' in col.lower()]
        
        for col in temp_cols:
            temp_data = pd.to_numeric(df[col], errors='coerce').dropna()
            if len(temp_data) > 0:
                temp_stats.append({
                    'Temperature Type': col.replace('PTAT: ', ''),
                    'Max (Â°C)': f"{temp_data.max():.2f}",
                    'Min (Â°C)': f"{temp_data.min():.2f}",
                    'Avg (Â°C)': f"{temp_data.mean():.2f}"
                })
        
        temp_df = pd.DataFrame(temp_stats) if temp_stats else None
        
        return freq_df, power_df, temp_df
    
    @staticmethod
    def calculate_temp_stats(log_data: LogData, x_limits=None):
        """è¨ˆç®—æº«åº¦çµ±è¨ˆæ•¸æ“š"""
        df = log_data.filter_by_time(x_limits)
        if df.empty:
            return pd.DataFrame()
        
        numeric_cols = df.select_dtypes(include=['number']).columns
        temp_cols = [col for col in numeric_cols if col not in ['Date', 'sec', 'RT', 'TIME']]
        
        stats_data = []
        for col in temp_cols:
            y_data = pd.to_numeric(df[col], errors='coerce')
            if not y_data.isna().all():
                t_max = y_data.max()
                t_avg = y_data.mean()
                
                display_name = col
                if display_name.startswith('YOKO: '):
                    display_name = display_name.replace('YOKO: ', '')
                elif display_name.startswith('PTAT: '):
                    display_name = display_name.replace('PTAT: ', '')
                elif display_name.startswith('GPU: '):
                    display_name = display_name.replace('GPU: ', '')
                
                if display_name.lower() in ['sec', 'time', 'rt', 'date']:
                    continue
                
                stats_data.append({
                    'é€šé“åç¨±': display_name,
                    'Tmax (Â°C)': f"{t_max:.2f}" if pd.notna(t_max) else "N/A",
                    'Tavg (Â°C)': f"{t_avg:.2f}" if pd.notna(t_avg) else "N/A"
                })
        
        return pd.DataFrame(stats_data)

# =============================================================================
# 5. Summaryæº«åº¦æ•´åˆè¡¨æ ¼ç”Ÿæˆå™¨ (Temperature Summary Generator) - å„ªåŒ–ç‰ˆ
# =============================================================================

class TemperatureSummaryGenerator:
    """æº«åº¦æ•´åˆæ‘˜è¦ç”Ÿæˆå™¨ - v10.3.8å„ªåŒ–ç‰ˆ"""
    
    @staticmethod
    def generate_summary_table(log_data_list: List[LogData]) -> pd.DataFrame:
        """ç”Ÿæˆæº«åº¦æ‘˜è¦è¡¨æ ¼ï¼ŒæŒ‰ç…§ç”¨æˆ¶æä¾›çš„æ ¼å¼"""
        summary_data = []
        ch_number = 1
        
        for log_data in log_data_list:
            df = log_data.df
            log_type = log_data.metadata.log_type
            filename = log_data.metadata.filename
            
            # ç²å–æ‰€æœ‰æ•¸å€¼å‹æ¬„ä½
            numeric_cols = df.select_dtypes(include=['number']).columns
            temp_cols = [col for col in numeric_cols if col not in ['Date', 'sec', 'RT', 'TIME']]
            
            # é‡å°PTAT logç‰¹æ®Šè™•ç† - åªä¿ç•™MSR Package Temperature
            if "PTAT" in log_type:
                temp_cols = [col for col in temp_cols if 'msr' in col.lower() and 'package' in col.lower() and 'temperature' in col.lower()]
            
            for col in temp_cols:
                temp_data = pd.to_numeric(df[col], errors='coerce').dropna()
                if len(temp_data) > 0:
                    max_temp = temp_data.max()
                    
                    # æ¸…ç†æ¬„ä½åç¨±
                    clean_col_name = col
                    if clean_col_name.startswith('YOKO: '):
                        clean_col_name = clean_col_name.replace('YOKO: ', '')
                    elif clean_col_name.startswith('PTAT: '):
                        clean_col_name = clean_col_name.replace('PTAT: ', '')
                    elif clean_col_name.startswith('GPU: '):
                        clean_col_name = clean_col_name.replace('GPU: ', '')
                    
                    # è·³ééæº«åº¦ç›¸é—œæ¬„ä½
                    if clean_col_name.lower() in ['sec', 'time', 'rt', 'date', 'iteration']:
                        continue
                    
                    # æ ¹æ“šä¸åŒlogé¡å‹è¨­å®šæè¿°
                    description = ""
                    if "GPU" in log_type:
                        if "Temperature" in clean_col_name:
                            description = "GPU Temperature"
                    elif "PTAT" in log_type:
                        if "MSR" in clean_col_name and "Package" in clean_col_name:
                            description = "CPU MSR Package Temperature"
                    else:  # YOKOGAWAæˆ–å…¶ä»–
                        # æ ¹æ“šæ¬„ä½åç¨±æ¨æ¸¬é¡å‹
                        if any(keyword in clean_col_name.upper() for keyword in ['CPU', 'PROCESSOR']):
                            description = "CPU"
                        elif any(keyword in clean_col_name.upper() for keyword in ['SSD', 'STORAGE']):
                            description = "SSD"
                        elif any(keyword in clean_col_name.upper() for keyword in ['DDR', 'MEMORY', 'RAM']):
                            description = "Memory"
                        elif any(keyword in clean_col_name.upper() for keyword in ['WIFI', 'WIRELESS']):
                            description = "WIFI"
                        else:
                            description = ""
                    
                    # æ ¼å¼åŒ–æº«åº¦å€¼
                    if max_temp > 200:  # å¯èƒ½æ˜¯æ¯«åº¦æˆ–å…¶ä»–å–®ä½
                        formatted_temp = f"{max_temp/1000:.1f}" if max_temp > 1000 else f"{max_temp:.1f}"
                    else:
                        formatted_temp = f"{max_temp:.1f}"
                    
                    # æ‰€æœ‰specç›¸é—œæ¬„ä½éƒ½ç•™ç©º
                    summary_data.append({
                        'Ch.': ch_number,
                        'Location': clean_col_name,
                        'Description': description,
                        'Spec location': "",  # ç•™ç©ºçµ¦ç”¨æˆ¶å¡«å¯«
                        'spec': "",  # ç•™ç©ºçµ¦ç”¨æˆ¶å¡«å¯«
                        'Ref Tc spec': "",  # ç•™ç©ºçµ¦ç”¨æˆ¶å¡«å¯«
                        'Result (Case Temp)': formatted_temp,
                        'Source File': filename,
                        'Log Type': log_type
                    })
                    
                    ch_number += 1
        
        return pd.DataFrame(summary_data)
    
    @staticmethod
    def format_summary_table_for_display(summary_df: pd.DataFrame) -> pd.DataFrame:
        """æ ¼å¼åŒ–è¡¨æ ¼ä»¥ç¬¦åˆé¡¯ç¤ºè¦æ±‚"""
        if summary_df.empty:
            return pd.DataFrame()
        
        # å‰µå»ºé¡¯ç¤ºç”¨çš„DataFrameï¼Œä¸åŒ…å«Source Fileå’ŒLog Type
        display_df = summary_df[['Ch.', 'Location', 'Description', 'Spec location', 'spec', 'Ref Tc spec', 'Result (Case Temp)']].copy()
        
        return display_df
    
    @staticmethod
    def get_summary_statistics(summary_df: pd.DataFrame) -> dict:
        """ç²å–æ‘˜è¦çµ±è¨ˆä¿¡æ¯"""
        if summary_df.empty:
            return {}
        
        try:
            # è½‰æ›æº«åº¦ç‚ºæ•¸å€¼
            temps = pd.to_numeric(summary_df['Result (Case Temp)'], errors='coerce').dropna()
            
            stats = {
                'total_channels': len(summary_df),
                'max_temp': temps.max() if len(temps) > 0 else 0,
                'min_temp': temps.min() if len(temps) > 0 else 0,
                'avg_temp': temps.mean() if len(temps) > 0 else 0,
                'files_analyzed': summary_df['Source File'].nunique() if 'Source File' in summary_df.columns else 0,
                'log_types': summary_df['Log Type'].unique().tolist() if 'Log Type' in summary_df.columns else []
            }
            
            return stats
        except Exception:
            return {
                'total_channels': len(summary_df),
                'max_temp': 0,
                'min_temp': 0,
                'avg_temp': 0,
                'files_analyzed': 0,
                'log_types': []
            }

# =============================================================================
# 6. åœ–è¡¨ç”Ÿæˆå±¤ (Chart Generation Layer)
# =============================================================================

class ChartGenerator:
    """åœ–è¡¨ç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_gpumon_chart(log_data: LogData, left_col: str, right_col: str, x_limits, left_y_limits=None, right_y_limits=None):
        """ç”ŸæˆGPUMonå°ˆç”¨åœ–è¡¨"""
        df = log_data.filter_by_time(x_limits)
        
        if df.empty or not left_col or left_col not in df.columns:
            return None
        if right_col and right_col != 'None' and right_col not in df.columns:
            return None
        
        df_chart = df.copy()
        df_chart.loc[:, 'left_val'] = pd.to_numeric(df_chart[left_col], errors='coerce')
        if right_col and right_col != 'None':
            df_chart.loc[:, 'right_val'] = pd.to_numeric(df_chart[right_col], errors='coerce')
        
        fig, ax1 = plt.subplots(figsize=(10.2, 5.1))
        
        title = f'GPUMon: {left_col.replace("GPU: ", "")} {"& " + right_col.replace("GPU: ", "") if right_col and right_col != "None" else ""}'
        plt.title(title, fontsize=14, fontweight='bold')
        
        x_axis_seconds = df_chart.index.total_seconds()
        color = 'tab:orange'
        ax1.set_xlabel('Elapsed Time (seconds)', fontsize=11)
        ax1.set_ylabel(left_col.replace("GPU: ", ""), color=color, fontsize=11)
        ax1.plot(x_axis_seconds, df_chart['left_val'], color=color, linewidth=2)
        ax1.tick_params(axis='y', labelcolor=color)
        ax1.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)
        
        if left_y_limits:
            ax1.set_ylim(left_y_limits)
        
        if right_col and right_col != 'None':
            ax2 = ax1.twinx()
            color = 'tab:green'
            ax2.set_ylabel(right_col.replace("GPU: ", ""), color=color, fontsize=11)
            ax2.plot(x_axis_seconds, df_chart['right_val'], color=color, linewidth=2)
            ax2.tick_params(axis='y', labelcolor=color)
            
            if right_y_limits:
                ax2.set_ylim(right_y_limits)
        
        if x_limits:
            ax1.set_xlim(x_limits)
        
        fig.tight_layout()
        return fig
    
    @staticmethod
    def generate_flexible_chart(log_data: LogData, left_col: str, right_col: str, x_limits, left_y_limits=None, right_y_limits=None):
        """ç”Ÿæˆéˆæ´»çš„é›™è»¸åœ–è¡¨"""
        df = log_data.filter_by_time(x_limits)
        
        if df.empty or not left_col or left_col not in df.columns:
            return None
        if right_col and right_col != 'None' and right_col not in df.columns:
            return None
        
        df_chart = df.copy()
        df_chart.loc[:, 'left_val'] = pd.to_numeric(df_chart[left_col], errors='coerce')
        if right_col and right_col != 'None':
            df_chart.loc[:, 'right_val'] = pd.to_numeric(df_chart[right_col], errors='coerce')
        
        fig, ax1 = plt.subplots(figsize=(10.2, 5.1))
        plt.title(f'{left_col} {"& " + right_col if right_col and right_col != "None" else ""}', fontsize=14, fontweight='bold')
        
        x_axis_seconds = df_chart.index.total_seconds()
        color = 'tab:blue'
        ax1.set_xlabel('Elapsed Time (seconds)', fontsize=11)
        ax1.set_ylabel(left_col, color=color, fontsize=11)
        ax1.plot(x_axis_seconds, df_chart['left_val'], color=color, linewidth=1.5)
        ax1.tick_params(axis='y', labelcolor=color)
        ax1.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)
        
        if left_y_limits:
            ax1.set_ylim(left_y_limits)
        
        if right_col and right_col != 'None':
            ax2 = ax1.twinx()
            color = 'tab:red'
            ax2.set_ylabel(right_col, color=color, fontsize=11)
            ax2.plot(x_axis_seconds, df_chart['right_val'], color=color, linewidth=1.5)
            ax2.tick_params(axis='y', labelcolor=color)
            
            if right_y_limits:
                ax2.set_ylim(right_y_limits)
        
        if x_limits:
            ax1.set_xlim(x_limits)
        
        fig.tight_layout()
        return fig
    
    @staticmethod
    def generate_yokogawa_temp_chart(log_data: LogData, x_limits=None, y_limits=None):
        """æ”¹é€²ç‰ˆYOKOGAWAæº«åº¦åœ–è¡¨"""
        df = log_data.filter_by_time(x_limits)
        
        if df.empty:
            return None
        
        fig, ax = plt.subplots(figsize=(10.2, 5.1))
        
        numeric_cols = df.select_dtypes(include=['number']).columns
        cols_to_plot = [col for col in numeric_cols if col not in ['Date', 'sec', 'RT', 'TIME']]
        
        max_channels = 15
        if len(cols_to_plot) > max_channels:
            cols_to_plot = cols_to_plot[:max_channels]
        
        for col in cols_to_plot:
            y_data = pd.to_numeric(df[col], errors='coerce')
            if not y_data.isna().all():
                display_name = col.replace('YOKO: ', '') if col.startswith('YOKO: ') else col
                ax.plot(df.index.total_seconds(), y_data, label=display_name, linewidth=1)
        
        ax.set_title("YOKOGAWA All Channel Temperature Plot", fontsize=14, fontweight='bold')
        ax.set_xlabel("Elapsed Time (seconds)", fontsize=11)
        ax.set_ylabel("Temperature (Â°C)", fontsize=11)
        ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)
        ax.legend(title="Channels", bbox_to_anchor=(1.04, 1), loc="upper left", fontsize=7)
        
        if x_limits:
            ax.set_xlim(x_limits)
        
        if y_limits:
            ax.set_ylim(y_limits)
        
        fig.tight_layout()
        return fig

# =============================================================================
# 7. UIæ¸²æŸ“å±¤ (UI Rendering Layer)
# =============================================================================

class GPUMonRenderer:
    """GPUMon UIæ¸²æŸ“å™¨"""
    
    def __init__(self, log_data: LogData):
        self.log_data = log_data
        self.stats_calc = StatisticsCalculator()
        self.chart_gen = ChartGenerator()
    
    def render_controls(self, file_index=None):
        """æ¸²æŸ“æ§åˆ¶é¢æ¿"""
        # ç²å–ç•¶å‰æª”æ¡ˆç´¢å¼•ç”¨æ–¼ç”Ÿæˆå”¯ä¸€key
        if file_index is None:
            file_index = getattr(st.session_state, 'current_file_index', 0)
        key_prefix = f"gpu_{file_index}_"
        
        st.sidebar.markdown("### âš™ï¸ GPUMon åœ–è¡¨è¨­å®š")
        
        numeric_columns = self.log_data.numeric_columns
        if not numeric_columns:
            return None, None, None, None, None
        
        st.sidebar.markdown("#### ğŸ¯ åƒæ•¸é¸æ“‡")
        
        default_left_index = 0
        for i, col in enumerate(numeric_columns):
            if 'Temperature GPU' in col and '(C)' in col:
                default_left_index = i
                break
        
        left_y_axis = st.sidebar.selectbox(
            "ğŸ“ˆ å·¦å´Yè»¸è®Šæ•¸", 
            options=numeric_columns, 
            index=default_left_index,
            key=f"{key_prefix}left_y_axis"
        )
        
        right_y_axis_options = ['None'] + numeric_columns
        default_right_index = 0
        for i, col in enumerate(right_y_axis_options):
            if 'TGP' in col and '(W)' in col:
                default_right_index = i
                break
        
        right_y_axis = st.sidebar.selectbox(
            "ğŸ“Š å³å´Yè»¸è®Šæ•¸ (å¯é¸)", 
            options=right_y_axis_options, 
            index=default_right_index,
            key=f"{key_prefix}right_y_axis"
        )
        
        st.sidebar.markdown("#### â±ï¸ æ™‚é–“ç¯„åœè¨­å®š")
        
        time_min, time_max = self.log_data.get_time_range()
        x_range = st.sidebar.slider(
            "é¸æ“‡æ™‚é–“ç¯„åœ (ç§’)",
            min_value=time_min,
            max_value=time_max,
            value=(time_min, time_max),
            step=1.0,
            key=f"{key_prefix}x_range"
        )
        
        st.sidebar.markdown("#### ğŸ“ Yè»¸ç¯„åœè¨­å®š")
        
        left_y_range_enabled = st.sidebar.checkbox("ğŸ”µ å•Ÿç”¨å·¦å´Yè»¸ç¯„åœé™åˆ¶", key=f"{key_prefix}left_y_range_enabled")
        left_y_range = None
        if left_y_range_enabled:
            col1, col2 = st.sidebar.columns(2)
            with col1:
                left_y_min = st.number_input("å·¦Yè»¸æœ€å°å€¼", value=0.0, key=f"{key_prefix}left_y_min")
            with col2:
                left_y_max = st.number_input("å·¦Yè»¸æœ€å¤§å€¼", value=100.0, key=f"{key_prefix}left_y_max")
            left_y_range = (left_y_min, left_y_max)
        
        right_y_range = None
        if right_y_axis and right_y_axis != 'None':
            right_y_range_enabled = st.sidebar.checkbox("ğŸ”´ å•Ÿç”¨å³å´Yè»¸ç¯„åœé™åˆ¶", key=f"{key_prefix}right_y_range_enabled")
            if right_y_range_enabled:
                col1, col2 = st.sidebar.columns(2)
                with col1:
                    right_y_min = st.number_input("å³Yè»¸æœ€å°å€¼", value=0.0, key=f"{key_prefix}right_y_min")
                with col2:
                    right_y_max = st.number_input("å³Yè»¸æœ€å¤§å€¼", value=100.0, key=f"{key_prefix}right_y_max")
                right_y_range = (right_y_min, right_y_max)
        
        return left_y_axis, right_y_axis, x_range, left_y_range, right_y_range
    
    def render_chart(self, left_col, right_col, x_range, left_y_range, right_y_range):
        """æ¸²æŸ“åœ–è¡¨"""
        st.markdown("### ğŸ“Š GPUMon æ€§èƒ½ç›£æ§åœ–è¡¨")
        
        chart = self.chart_gen.generate_gpumon_chart(
            self.log_data, left_col, right_col, x_range, left_y_range, right_y_range
        )
        if chart:
            st.pyplot(chart)
        else:
            st.warning("ç„¡æ³•ç”Ÿæˆåœ–è¡¨ï¼Œè«‹æª¢æŸ¥åƒæ•¸è¨­å®š")
    
    def render_statistics(self, x_range):
        """æ¸²æŸ“çµ±è¨ˆæ•¸æ“š"""
        st.markdown("### ğŸ“ˆ GPUMon çµ±è¨ˆæ•¸æ“š")
        
        temp_stats, power_stats, freq_stats, util_stats = self.stats_calc.calculate_gpumon_stats(
            self.log_data, x_range
        )
        
        if temp_stats is not None and not temp_stats.empty:
            st.markdown("#### ğŸŒ¡ï¸ GPU æº«åº¦çµ±è¨ˆ")
            st.dataframe(temp_stats, use_container_width=True, hide_index=True)
        
        if power_stats is not None and not power_stats.empty:
            st.markdown("#### ğŸ”‹ GPU åŠŸè€—çµ±è¨ˆ")
            st.dataframe(power_stats, use_container_width=True, hide_index=True)
        
        if freq_stats is not None and not freq_stats.empty:
            st.markdown("#### âš¡ GPU é »ç‡çµ±è¨ˆ")
            st.dataframe(freq_stats, use_container_width=True, hide_index=True)
        
        if util_stats is not None and not util_stats.empty:
            st.markdown("#### ğŸ“Š GPU ä½¿ç”¨ç‡çµ±è¨ˆ")
            st.dataframe(util_stats, use_container_width=True, hide_index=True)
    
    def render(self, file_index=None):
        """æ¸²æŸ“å®Œæ•´UI"""
        st.markdown("""
        <div class="gpumon-box">
            <h4>ğŸ® GPUMon Log è§£æå®Œæˆï¼</h4>
            <p>å·²è­˜åˆ¥ç‚ºGPUç›£æ§æ•¸æ“šï¼ŒåŒ…å«æº«åº¦ã€åŠŸè€—ã€é »ç‡ç­‰æŒ‡æ¨™</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.success(f"ğŸ“Š æ•¸æ“šè¼‰å…¥ï¼š{self.log_data.metadata.rows} è¡Œ Ã— {self.log_data.metadata.columns} åˆ—")
        
        left_col, right_col, x_range, left_y_range, right_y_range = self.render_controls(file_index)
        
        if left_col:
            self.render_chart(left_col, right_col, x_range, left_y_range, right_y_range)
            self.render_statistics(x_range)

class PTATRenderer:
    """PTAT UIæ¸²æŸ“å™¨"""
    
    def __init__(self, log_data: LogData):
        self.log_data = log_data
        self.stats_calc = StatisticsCalculator()
        self.chart_gen = ChartGenerator()
    
    def render_controls(self, file_index=None):
        """æ¸²æŸ“æ§åˆ¶é¢æ¿"""
        # ç²å–ç•¶å‰æª”æ¡ˆç´¢å¼•ç”¨æ–¼ç”Ÿæˆå”¯ä¸€key
        if file_index is None:
            file_index = getattr(st.session_state, 'current_file_index', 0)
        key_prefix = f"ptat_{file_index}_"
        
        st.sidebar.markdown("### âš™ï¸ PTAT åœ–è¡¨è¨­å®š")
        
        numeric_columns = self.log_data.numeric_columns
        if not numeric_columns:
            return None, None, None, None, None
        
        st.sidebar.markdown("#### ğŸ¯ åƒæ•¸é¸æ“‡")
        
        default_left_index = 0
        for i, col in enumerate(numeric_columns):
            if 'MSR' in col and 'Package' in col and 'Temperature' in col:
                default_left_index = i
                break
        
        left_y_axis = st.sidebar.selectbox("ğŸ“ˆ å·¦å´Yè»¸è®Šæ•¸", options=numeric_columns, index=default_left_index, key=f"{key_prefix}left_y_axis")
        
        right_y_axis_options = ['None'] + numeric_columns
        default_right_index = 0
        for i, col in enumerate(right_y_axis_options):
            if 'Package' in col and 'Power' in col:
                default_right_index = i
                break
        
        right_y_axis = st.sidebar.selectbox("ğŸ“Š å³å´Yè»¸è®Šæ•¸ (å¯é¸)", options=right_y_axis_options, index=default_right_index, key=f"{key_prefix}right_y_axis")
        
        st.sidebar.markdown("#### â±ï¸ æ™‚é–“ç¯„åœè¨­å®š")
        
        time_min, time_max = self.log_data.get_time_range()
        x_range = st.sidebar.slider("é¸æ“‡æ™‚é–“ç¯„åœ (ç§’)", min_value=time_min, max_value=time_max, value=(time_min, time_max), step=1.0, key=f"{key_prefix}x_range")
        
        st.sidebar.markdown("#### ğŸ“ Yè»¸ç¯„åœè¨­å®š")
        
        left_y_range_enabled = st.sidebar.checkbox("ğŸ”µ å•Ÿç”¨å·¦å´Yè»¸ç¯„åœé™åˆ¶", key=f"{key_prefix}left_y_range_enabled")
        left_y_range = None
        if left_y_range_enabled:
            col1, col2 = st.sidebar.columns(2)
            with col1:
                left_y_min = st.number_input("å·¦Yè»¸æœ€å°å€¼", value=0.0, key=f"{key_prefix}left_y_min")
            with col2:
                left_y_max = st.number_input("å·¦Yè»¸æœ€å¤§å€¼", value=100.0, key=f"{key_prefix}left_y_max")
            left_y_range = (left_y_min, left_y_max)
        
        right_y_range = None
        if right_y_axis and right_y_axis != 'None':
            right_y_range_enabled = st.sidebar.checkbox("ğŸ”´ å•Ÿç”¨å³å´Yè»¸ç¯„åœé™åˆ¶", key=f"{key_prefix}right_y_range_enabled")
            if right_y_range_enabled:
                col1, col2 = st.sidebar.columns(2)
                with col1:
                    right_y_min = st.number_input("å³Yè»¸æœ€å°å€¼", value=0.0, key=f"{key_prefix}right_y_min")
                with col2:
                    right_y_max = st.number_input("å³Yè»¸æœ€å¤§å€¼", value=100.0, key=f"{key_prefix}right_y_max")
                right_y_range = (right_y_min, right_y_max)
        
        return left_y_axis, right_y_axis, x_range, left_y_range, right_y_range
    
    def render(self, file_index=None):
        """æ¸²æŸ“å®Œæ•´UI"""
        st.markdown("""
        <div class="info-box">
            <h4>ğŸ–¥ï¸ PTAT Log è§£æå®Œæˆï¼</h4>
            <p>å·²è­˜åˆ¥ç‚ºCPUæ€§èƒ½ç›£æ§æ•¸æ“šï¼ŒåŒ…å«é »ç‡ã€åŠŸè€—ã€æº«åº¦ç­‰æŒ‡æ¨™</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.success(f"ğŸ“Š æ•¸æ“šè¼‰å…¥ï¼š{self.log_data.metadata.rows} è¡Œ Ã— {self.log_data.metadata.columns} åˆ—")
        
        left_y_axis, right_y_axis, x_range, left_y_range, right_y_range = self.render_controls(file_index)
        
        if left_y_axis:
            st.markdown("### ğŸ“Š PTAT CPU æ€§èƒ½ç›£æ§åœ–è¡¨")
            chart = self.chart_gen.generate_flexible_chart(self.log_data, left_y_axis, right_y_axis, x_range, left_y_range, right_y_range)
            if chart:
                st.pyplot(chart)
            
            st.markdown("### ğŸ“ˆ PTAT çµ±è¨ˆæ•¸æ“š")
            freq_stats, power_stats, temp_stats = self.stats_calc.calculate_ptat_stats(self.log_data, x_range)
            
            if freq_stats is not None and not freq_stats.empty:
                st.markdown("#### âš¡ CPU é »ç‡çµ±è¨ˆ")
                st.dataframe(freq_stats, use_container_width=True, hide_index=True)
            
            if power_stats is not None and not power_stats.empty:
                st.markdown("#### ğŸ”‹ Package åŠŸè€—çµ±è¨ˆ")
                st.dataframe(power_stats, use_container_width=True, hide_index=True)
            
            if temp_stats is not None and not temp_stats.empty:
                st.markdown("#### ğŸŒ¡ï¸ Package æº«åº¦çµ±è¨ˆ")
                st.dataframe(temp_stats, use_container_width=True, hide_index=True)

class YokogawaRenderer:
    """YOKOGAWA UIæ¸²æŸ“å™¨ - v10.3.8 è¶…ç°¡æ½”ç‰ˆ"""
    
    def __init__(self, log_data: LogData):
        self.log_data = log_data
        self.stats_calc = StatisticsCalculator()
        self.chart_gen = ChartGenerator()
    
    def render(self, file_index=None):
        """æ¸²æŸ“å®Œæ•´UI"""
        # ç²å–ç•¶å‰æª”æ¡ˆç´¢å¼•ç”¨æ–¼ç”Ÿæˆå”¯ä¸€key
        if file_index is None:
            file_index = getattr(st.session_state, 'current_file_index', 0)
        key_prefix = f"yoko_{file_index}_"
        
        st.markdown("""
        <div class="success-box">
            <h4>ğŸ“Š YOKOGAWA Log è§£æå®Œæˆï¼ (v10.3.8 å¤šæª”æ¡ˆç¨ç«‹åˆ†æç‰ˆ)</h4>
            <p>âœ¨ æ™ºèƒ½è§£ææˆåŠŸï¼Œç•Œé¢æ¸…çˆ½ï¼Œè©³ç´°æ—¥èªŒå·²éš±è—åœ¨ä¸‹æ‹‰é¸å–®ä¸­</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.success(f"ğŸ“Š æ•¸æ“šè¼‰å…¥ï¼š{self.log_data.metadata.rows} è¡Œ Ã— {self.log_data.metadata.columns} åˆ—")
        
        st.sidebar.markdown("### âš™ï¸ YOKOGAWA åœ–è¡¨è¨­å®š")
        chart_mode = st.sidebar.radio("ğŸ“ˆ åœ–è¡¨æ¨¡å¼", ["å…¨é€šé“æº«åº¦åœ–", "è‡ªå®šç¾©é›™è»¸åœ–"], key=f"{key_prefix}chart_mode")
        
        time_min, time_max = self.log_data.get_time_range()
        x_range = st.sidebar.slider("é¸æ“‡æ™‚é–“ç¯„åœ (ç§’)", min_value=time_min, max_value=time_max, value=(time_min, time_max), step=1.0, key=f"{key_prefix}x_range")
        
        if chart_mode == "å…¨é€šé“æº«åº¦åœ–":
            st.sidebar.markdown("#### ğŸ“ Yè»¸ç¯„åœè¨­å®š")
            y_range_enabled = st.sidebar.checkbox("å•Ÿç”¨Yè»¸ç¯„åœé™åˆ¶", key=f"{key_prefix}y_range_enabled")
            y_range = None
            if y_range_enabled:
                col1, col2 = st.sidebar.columns(2)
                with col1:
                    y_min = st.number_input("Yè»¸æœ€å°å€¼", value=0.0, key=f"{key_prefix}y_min")
                with col2:
                    y_max = st.number_input("Yè»¸æœ€å¤§å€¼", value=100.0, key=f"{key_prefix}y_max")
                y_range = (y_min, y_max)
            
            st.markdown("### ğŸ“Š YOKOGAWA å…¨é€šé“æº«åº¦åœ–è¡¨")
            chart = self.chart_gen.generate_yokogawa_temp_chart(self.log_data, x_range, y_range)
            if chart:
                st.pyplot(chart)
        
        else:
            numeric_columns = self.log_data.numeric_columns
            if numeric_columns:
                st.sidebar.markdown("#### ğŸ¯ åƒæ•¸é¸æ“‡")
                left_y_axis = st.sidebar.selectbox("ğŸ“ˆ å·¦å´Yè»¸è®Šæ•¸", options=numeric_columns, index=0, key=f"{key_prefix}left_y_axis")
                right_y_axis_options = ['None'] + numeric_columns
                right_y_axis = st.sidebar.selectbox("ğŸ“Š å³å´Yè»¸è®Šæ•¸ (å¯é¸)", options=right_y_axis_options, index=0, key=f"{key_prefix}right_y_axis")
                
                st.sidebar.markdown("#### ğŸ“ Yè»¸ç¯„åœè¨­å®š")
                
                left_y_range_enabled = st.sidebar.checkbox("ğŸ”µ å•Ÿç”¨å·¦å´Yè»¸ç¯„åœé™åˆ¶", key=f"{key_prefix}left_y_range_enabled")
                left_y_range = None
                if left_y_range_enabled:
                    col1, col2 = st.sidebar.columns(2)
                    with col1:
                        left_y_min = st.number_input("å·¦Yè»¸æœ€å°å€¼", value=0.0, key=f"{key_prefix}left_y_min")
                    with col2:
                        left_y_max = st.number_input("å·¦Yè»¸æœ€å¤§å€¼", value=100.0, key=f"{key_prefix}left_y_max")
                    left_y_range = (left_y_min, left_y_max)
                
                right_y_range = None
                if right_y_axis and right_y_axis != 'None':
                    right_y_range_enabled = st.sidebar.checkbox("ğŸ”´ å•Ÿç”¨å³å´Yè»¸ç¯„åœé™åˆ¶", key=f"{key_prefix}right_y_range_enabled")
                    if right_y_range_enabled:
                        col1, col2 = st.sidebar.columns(2)
                        with col1:
                            right_y_min = st.number_input("å³Yè»¸æœ€å°å€¼", value=0.0, key=f"{key_prefix}right_y_min")
                        with col2:
                            right_y_max = st.number_input("å³Yè»¸æœ€å¤§å€¼", value=100.0, key=f"{key_prefix}right_y_max")
                        right_y_range = (right_y_min, right_y_max)
                
                st.markdown("### ğŸ“Š YOKOGAWA è‡ªå®šç¾©åœ–è¡¨")
                chart = self.chart_gen.generate_flexible_chart(self.log_data, left_y_axis, right_y_axis, x_range, left_y_range, right_y_range)
                if chart:
                    st.pyplot(chart)
        
        st.markdown("### ğŸ“ˆ æº«åº¦çµ±è¨ˆæ•¸æ“š")
        temp_stats = self.stats_calc.calculate_temp_stats(self.log_data, x_range)
        if not temp_stats.empty:
            st.dataframe(temp_stats, use_container_width=True, hide_index=True)

class SummaryRenderer:
    """Summary UIæ¸²æŸ“å™¨ - v10.3.8ç°¡åŒ–ç‰ˆ (åƒ…ä¿ç•™HTMLå¸¶è¡¨æ ¼æ¡†çš„æ•¸æ“šå‘ˆç¾)"""
    
    def __init__(self, log_data_list: List[LogData]):
        self.log_data_list = log_data_list
        self.summary_gen = TemperatureSummaryGenerator()
    
    def render(self):
        """æ¸²æŸ“Summaryæ¨™ç±¤é å…§å®¹ - ç°¡åŒ–ç‰ˆ"""
        st.markdown("""
        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 1.5rem; border-radius: 10px; margin-bottom: 2rem; color: white;">
            <h3>ğŸ“‹ æº«åº¦æ•´åˆæ‘˜è¦å ±å‘Š</h3>
            <p>ğŸ¯ æ•´åˆæ‰€æœ‰æª”æ¡ˆçš„æº«åº¦æ•¸æ“šï¼ŒæŒ‰ç…§æ¨™æº–æ ¼å¼é¡¯ç¤ºæœ€é«˜æº«åº¦</p>
        </div>
        """, unsafe_allow_html=True)
        
        # ç”Ÿæˆæ‘˜è¦è¡¨æ ¼
        summary_df = self.summary_gen.generate_summary_table(self.log_data_list)
        
        if summary_df.empty:
            st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°å¯ç”¨çš„æº«åº¦æ•¸æ“š")
            return
        
        # é¡¯ç¤ºæª”æ¡ˆä¾†æºä¿¡æ¯
        stats = self.summary_gen.get_summary_statistics(summary_df)
        if 'log_types' in stats and stats['log_types']:
            with st.expander("ğŸ“‚ æª”æ¡ˆä¾†æºè©³æƒ…", expanded=False):
                unique_files = summary_df['Source File'].unique() if 'Source File' in summary_df.columns else []
                for i, filename in enumerate(unique_files, 1):
                    file_data = summary_df[summary_df['Source File'] == filename] if 'Source File' in summary_df.columns else pd.DataFrame()
                    if not file_data.empty:
                        log_type = file_data['Log Type'].iloc[0] if 'Log Type' in file_data.columns else 'Unknown'
                        channel_count = len(file_data)
                        
                        # æ·»åŠ é¡å‹emoji
                        if "GPUMon" in log_type:
                            emoji = "ğŸ®"
                        elif "PTAT" in log_type:
                            emoji = "ğŸ–¥ï¸"
                        elif "YOKOGAWA" in log_type:
                            emoji = "ğŸ“Š"
                        else:
                            emoji = "ğŸ“„"
                        
                        st.write(f"**{i}.** {emoji} `{filename}` ({log_type}) - {channel_count} å€‹ç›£æ§é»")
        
        # é¡¯ç¤ºæ•´åˆè¡¨æ ¼
        st.markdown("### ğŸ“‹ æº«åº¦ç›£æ§é»æ•´åˆè¡¨æ ¼")
        
        # æ ¼å¼åŒ–é¡¯ç¤ºè¡¨æ ¼
        display_df = self.summary_gen.format_summary_table_for_display(summary_df)
        
        if not display_df.empty:
            # æº–å‚™HTMLè¡¨æ ¼
            html_table = self._prepare_html_table(display_df)
            
            # HTMLè¡¨æ ¼é è¦½ï¼ˆé è¨­é–‹å•Ÿï¼‰
            with st.expander("ğŸ” HTMLè¡¨æ ¼é è¦½ï¼ˆå¯ç›´æ¥è¤‡è£½ï¼‰", expanded=True):
                st.markdown("**ä»¥ä¸‹æ˜¯å¸¶é‚Šæ¡†çš„HTMLè¡¨æ ¼ï¼Œå¯ç›´æ¥é¸ä¸­è¤‡è£½ï¼š**")
                st.markdown(html_table, unsafe_allow_html=True)
                st.info("ğŸ’¡ æç¤ºï¼šåœ¨ä¸Šæ–¹è¡¨æ ¼ä¸ŠæŒ‰ä½æ»‘é¼ å·¦éµæ‹–æ‹½é¸ä¸­æ•´å€‹è¡¨æ ¼ï¼Œç„¶å¾ŒCtrl+Cè¤‡è£½ï¼Œåˆ°Wordä¸­Ctrl+Vè²¼ä¸Š")
        
        else:
            st.error("âŒ ç„¡æ³•ç”Ÿæˆæ‘˜è¦è¡¨æ ¼")
    
    def _prepare_html_table(self, display_df: pd.DataFrame) -> str:
        """æº–å‚™å¸¶é‚Šæ¡†çš„HTMLè¡¨æ ¼æ ¼å¼"""
        if display_df.empty:
            return ""
        
        # å‰µå»ºHTMLè¡¨æ ¼
        html_parts = []
        
        # æ·»åŠ CSSæ¨£å¼
        html_parts.append("""
        <style>
        .temp-table {
            border-collapse: collapse;
            width: 100%;
            margin: 10px 0;
            font-family: Arial, sans-serif;
            font-size: 12px;
        }
        .temp-table th, .temp-table td {
            border: 1px solid #333333;
            padding: 8px;
            text-align: center;
            vertical-align: middle;
        }
        .temp-table th {
            background-color: #f2f2f2;
            font-weight: bold;
            color: #333333;
        }
        .temp-table td {
            background-color: #ffffff;
        }
        .temp-table tr:nth-child(even) td {
            background-color: #f9f9f9;
        }
        </style>
        """)
        
        # é–‹å§‹è¡¨æ ¼
        html_parts.append('<table class="temp-table">')
        
        # è¡¨æ ¼æ¨™é¡Œè¡Œ
        html_parts.append('<thead>')
        html_parts.append('<tr>')
        for header in display_df.columns:
            html_parts.append(f'<th>{header}</th>')
        html_parts.append('</tr>')
        html_parts.append('</thead>')
        
        # è¡¨æ ¼æ•¸æ“šè¡Œ
        html_parts.append('<tbody>')
        for _, row in display_df.iterrows():
            html_parts.append('<tr>')
            for value in row:
                # è™•ç†ç©ºå€¼
                cell_value = str(value) if pd.notna(value) else ""
                html_parts.append(f'<td>{cell_value}</td>')
            html_parts.append('</tr>')
        html_parts.append('</tbody>')
        
        # çµæŸè¡¨æ ¼
        html_parts.append('</table>')
        
        return "\n".join(html_parts)

# =============================================================================
# 8. UIå·¥å»  (UI Factory)
# =============================================================================

class RendererFactory:
    """UIæ¸²æŸ“å™¨å·¥å» """
    
    @staticmethod
    def create_renderer(log_data: LogData):
        """æ ¹æ“šlogé¡å‹å‰µå»ºå°æ‡‰çš„æ¸²æŸ“å™¨"""
        log_type = log_data.metadata.log_type
        
        if log_type == "GPUMon Log":
            return GPUMonRenderer(log_data)
        elif log_type == "PTAT Log":
            return PTATRenderer(log_data)
        elif log_type == "YOKOGAWA Log":
            return YokogawaRenderer(log_data)
        else:
            return None

# =============================================================================
# 9. ä¸»æ‡‰ç”¨ç¨‹å¼ (Main Application) - v10.3.8 å¤šæª”æ¡ˆç¨ç«‹åˆ†æ + Summaryæ•´åˆç‰ˆ (ç°¡åŒ–ç‰ˆ)
# =============================================================================

def display_version_info():
    """é¡¯ç¤ºç‰ˆæœ¬è³‡è¨Š"""
    with st.expander("ğŸ“‹ ç‰ˆæœ¬è³‡è¨Š", expanded=False):
        st.markdown(f"""
        **ç•¶å‰ç‰ˆæœ¬ï¼š{VERSION}** | **ç™¼å¸ƒæ—¥æœŸï¼š{VERSION_DATE}**
        
        ### âœ¨ ä¸»è¦åŠŸèƒ½
        
        - **ğŸ® GPUMon Log** - GPUæ€§èƒ½ç›£æ§æ•¸æ“šè§£æèˆ‡è¦–è¦ºåŒ–
        - **ğŸ–¥ï¸ PTAT Log** - CPUæ€§èƒ½ç›£æ§æ•¸æ“šè§£æèˆ‡è¦–è¦ºåŒ–  
        - **ğŸ“Š YOKOGAWA Log** - å¤šé€šé“æº«åº¦è¨˜éŒ„å„€æ•¸æ“šè§£æèˆ‡è¦–è¦ºåŒ–
        - **ğŸ“‹ Summaryæ•´åˆ** - å¤šæª”æ¡ˆæº«åº¦æ•¸æ“šæ•´åˆï¼Œç”Ÿæˆå¸¶é‚Šæ¡†HTMLè¡¨æ ¼
        - **ğŸ“ˆ ç¨ç«‹åˆ†æ** - æ¯å€‹æª”æ¡ˆéƒ½æœ‰å°ˆå±¬çš„åœ–è¡¨æ§åˆ¶å’Œçµ±è¨ˆåˆ†æ
        
        ### ğŸ¯ æ ¸å¿ƒç‰¹è‰²
        
        - **æ™ºèƒ½è§£æ** - è‡ªå‹•è­˜åˆ¥ä¸åŒé¡å‹çš„Logæª”æ¡ˆæ ¼å¼
        - **å¤šæª”æ¡ˆæ”¯æ´** - åŒæ™‚è™•ç†å¤šå€‹æª”æ¡ˆï¼Œç¨ç«‹åˆ†æ
        - **å¸¶é‚Šæ¡†è¡¨æ ¼** - Summaryé é¢æä¾›å¯ç›´æ¥è¤‡è£½åˆ°Wordçš„HTMLè¡¨æ ¼
        - **å³æ™‚äº’å‹•** - æ™‚é–“ç¯„åœå’Œåƒæ•¸èª¿æ•´å³æ™‚æ›´æ–°åœ–è¡¨æ•¸æ“š
        """)


def main():
    """ä¸»ç¨‹å¼ - v10.3.8 Multi-File Analysis with Summary (Simplified)"""
    st.set_page_config(
        page_title="æº«åº¦æ•¸æ“šè¦–è¦ºåŒ–å¹³å°",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # CSSæ¨£å¼
    st.markdown("""
    <style>
        .main-header {
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            padding: 1.5rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            text-align: center;
            color: white;
        }
        .success-box {
            background-color: #d4edda;
            border: 1px solid #c3e6cb;
            color: #155724;
            padding: 1rem;
            border-radius: 8px;
            margin: 1rem 0;
        }
        .info-box {
            background-color: #d1ecf1;
            border: 1px solid #bee5eb;
            color: #0c5460;
            padding: 1rem;
            border-radius: 8px;
            margin: 1rem 0;
        }
        .gpumon-box {
            background-color: #fff3cd;
            border: 1px solid #ffeaa7;
            color: #856404;
            padding: 1rem;
            border-radius: 8px;
            margin: 1rem 0;
        }
        .stMetric {
            background-color: #f8f9fa;
            padding: 0.5rem;
            border-radius: 0.25rem;
            border: 1px solid #dee2e6;
        }
        .temp-summary-table {
            font-size: 0.9em;
        }
        .temp-summary-table th {
            background-color: #f0f2f6;
            font-weight: bold;
            text-align: center;
        }
        .temp-summary-table td {
            text-align: center;
        }
    </style>
    """, unsafe_allow_html=True)
    
    # æ¨™é¡Œ
    st.markdown(f"""
    <div class="main-header">
        <h1>ğŸ“Š æº«åº¦æ•¸æ“šè¦–è¦ºåŒ–å¹³å°</h1>
        <p>æ™ºèƒ½è§£æ YOKOGAWAã€PTATã€GPUMon Log æ–‡ä»¶ | å¤šæª”æ¡ˆç¨ç«‹åˆ†æ + Summaryæ•´åˆ (ç°¡åŒ–ç‰ˆ)</p>
        <p><strong>{VERSION}</strong> | {VERSION_DATE}</p>
    </div>
    """, unsafe_allow_html=True)
    
    display_version_info()
    
    # åˆå§‹åŒ–è§£æå™¨è¨»å†Šç³»çµ±
    parser_registry = ParserRegistry()
    parser_registry.register(GPUMonParser())
    parser_registry.register(PTATParser())
    parser_registry.register(YokogawaParser())  # å…œåº•è§£æå™¨
    
    # å´é‚Šæ¬„
    st.sidebar.markdown("### ğŸ›ï¸ æ§åˆ¶é¢æ¿")
    st.sidebar.markdown("---")
    
    uploaded_files = st.sidebar.file_uploader(
        "ğŸ“ ä¸Šå‚³Log File (å¯å¤šé¸)", 
        type=['csv', 'xlsx'], 
        accept_multiple_files=True,
        help="v10.3.8 ç°¡åŒ–ç‰ˆï¼šå¤šæª”æ¡ˆç¨ç«‹åˆ†æ + Summaryæ•´åˆï¼Œå°ˆæ³¨å¸¶é‚Šæ¡†è¡¨æ ¼è¤‡è£½"
    )
    
    # é¡¯ç¤ºè¨ªå•è¨ˆæ•¸å™¨
    display_visit_counter()
    
    if uploaded_files:
        # é¡¯ç¤ºä¸Šå‚³æª”æ¡ˆè³‡è¨Š
        st.sidebar.markdown("---")
        st.sidebar.markdown("### ğŸ“‚ å·²ä¸Šå‚³æª”æ¡ˆ")
        for i, file in enumerate(uploaded_files, 1):
            file_size = len(file.getvalue()) / 1024
            st.sidebar.markdown(f"**{i}.** `{file.name}` ({file_size:.1f} KB)")
        
        st.sidebar.markdown("---")
        
        # è§£ææª”æ¡ˆ - è¶…ç°¡æ½”ç‰ˆæœ¬
        log_data_list = []
        for uploaded_file in uploaded_files:
            log_data = parser_registry.parse_file(uploaded_file)
            if log_data:
                log_data_list.append(log_data)
        
        if not log_data_list:
            st.error("âŒ ç„¡æ³•è§£æä»»ä½•æª”æ¡ˆ")
            return
        
        # æ ¹æ“šæª”æ¡ˆæ•¸é‡æ±ºå®šUIæ¨¡å¼
        if len(log_data_list) == 1:
            # å–®æª”æ¡ˆæ¨¡å¼
            log_data = log_data_list[0]
            renderer = RendererFactory.create_renderer(log_data)
            
            if renderer:
                renderer.render(file_index=0)
            else:
                st.error(f"ä¸æ”¯æ´çš„Logé¡å‹: {log_data.metadata.log_type}")
        
        else:
            # å¤šæª”æ¡ˆæ¨¡å¼ - æ¯å€‹æª”æ¡ˆç¨ç«‹é¡¯ç¤º + Summaryæ•´åˆ
            st.success(f"ğŸ“Š å¤šæª”æ¡ˆåˆ†ææ¨¡å¼ï¼šæˆåŠŸè§£æ {len(log_data_list)} å€‹æª”æ¡ˆ")
            
            # å‰µå»ºæ¨™ç±¤é ï¼Œæ¯å€‹æª”æ¡ˆä¸€å€‹æ¨™ç±¤ + Summaryæ¨™ç±¤
            tab_names = []
            
            # é¦–å…ˆæ·»åŠ Summaryæ¨™ç±¤
            tab_names.append("ğŸ“‹ Summary")
            
            # ç„¶å¾Œæ·»åŠ å„å€‹æª”æ¡ˆçš„æ¨™ç±¤
            for i, log_data in enumerate(log_data_list):
                # ç”Ÿæˆæ¨™ç±¤åç¨±
                filename = log_data.metadata.filename
                log_type = log_data.metadata.log_type
                
                # ç¸®çŸ­æª”æ¡ˆåç¨±ä»¥é©æ‡‰æ¨™ç±¤é¡¯ç¤º
                short_name = filename
                if len(filename) > 15:
                    name_parts = filename.split('.')
                    if len(name_parts) > 1:
                        short_name = name_parts[0][:12] + "..." + name_parts[-1]
                    else:
                        short_name = filename[:12] + "..."
                
                # æ·»åŠ é¡å‹emoji
                if "GPUMon" in log_type:
                    tab_name = f"ğŸ® {short_name}"
                elif "PTAT" in log_type:
                    tab_name = f"ğŸ–¥ï¸ {short_name}"
                elif "YOKOGAWA" in log_type:
                    tab_name = f"ğŸ“Š {short_name}"
                else:
                    tab_name = f"ğŸ“„ {short_name}"
                
                tab_names.append(tab_name)
            
            # å‰µå»ºæ¨™ç±¤é 
            tabs = st.tabs(tab_names)
            
            # é¦–å…ˆæ¸²æŸ“Summaryæ¨™ç±¤é 
            with tabs[0]:
                summary_renderer = SummaryRenderer(log_data_list)
                summary_renderer.render()
            
            # ç„¶å¾Œç‚ºæ¯å€‹æª”æ¡ˆæ¸²æŸ“ç¨ç«‹çš„å…§å®¹
            for i, (tab, log_data) in enumerate(zip(tabs[1:], log_data_list)):
                with tab:
                    # é¡¯ç¤ºæª”æ¡ˆè³‡è¨Š
                    st.markdown(f"""
                    <div style="background-color: #f0f8ff; padding: 1rem; border-radius: 8px; margin-bottom: 1rem; border-left: 4px solid #1f77b4;">
                        <h4>ğŸ“ æª”æ¡ˆè³‡è¨Š</h4>
                        <p><strong>æª”æ¡ˆåç¨±ï¼š</strong> {log_data.metadata.filename}</p>
                        <p><strong>æª”æ¡ˆé¡å‹ï¼š</strong> {log_data.metadata.log_type}</p>
                        <p><strong>æ•¸æ“šè¦æ¨¡ï¼š</strong> {log_data.metadata.rows} è¡Œ Ã— {log_data.metadata.columns} åˆ—</p>
                        <p><strong>æª”æ¡ˆå¤§å°ï¼š</strong> {log_data.metadata.file_size_kb:.1f} KB</p>
                        <p><strong>æ™‚é–“ç¯„åœï¼š</strong> {log_data.metadata.time_range}</p>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # ç‚ºæ¯å€‹æª”æ¡ˆå‰µå»ºç¨ç«‹çš„æ¸²æŸ“å™¨
                    renderer = RendererFactory.create_renderer(log_data)
                    
                    if renderer:
                        # æ¸²æŸ“è©²æª”æ¡ˆçš„å®Œæ•´UIï¼Œå‚³éæ­£ç¢ºçš„file_index
                        renderer.render(file_index=i)
                        
                    else:
                        st.error(f"ä¸æ”¯æ´çš„Logé¡å‹: {log_data.metadata.log_type}")
                        
                        # é¡¯ç¤ºåŸºæœ¬ä¿¡æ¯ä½œç‚ºå‚™ç”¨
                        st.markdown("### ğŸ“Š åŸºæœ¬æ•¸æ“šé è¦½")
                        if not log_data.df.empty:
                            st.write("**æ¬„ä½åˆ—è¡¨ï¼š**")
                            for col in log_data.df.columns:
                                st.write(f"- {col}")
                            
                            st.write("**æ•¸æ“šæ¨£æœ¬ï¼ˆå‰5è¡Œï¼‰ï¼š**")
                            st.dataframe(log_data.df.head(), use_container_width=True)
            
            # åœ¨æ¨™ç±¤é å¤–æä¾›æª”æ¡ˆé¸æ“‡å™¨ï¼ˆç”¨æ–¼å´é‚Šæ¬„æ§åˆ¶ï¼‰
            st.sidebar.markdown("---")
            st.sidebar.markdown("### ğŸ›ï¸ å¤šæª”æ¡ˆæ§åˆ¶")
            
            selected_file_index = st.sidebar.selectbox(
                "é¸æ“‡è¦æ§åˆ¶çš„æª”æ¡ˆ",
                options=range(len(log_data_list)),
                format_func=lambda x: f"{log_data_list[x].metadata.filename} ({log_data_list[x].metadata.log_type})",
                help="é¸æ“‡è¦åœ¨å´é‚Šæ¬„ä¸­æ§åˆ¶çš„æª”æ¡ˆ"
            )
            
            st.sidebar.info(f"ğŸ’¡ ç•¶å‰é¸æ“‡ï¼š{log_data_list[selected_file_index].metadata.filename}")
            # æ³¨æ„ï¼šé€™å€‹é¸æ“‡å™¨ä¸»è¦ç”¨æ–¼é¡¯ç¤ºä¿¡æ¯ï¼Œå¯¦éš›çš„æ§åˆ¶æ˜¯åœ¨å„å€‹tabä¸­ç¨ç«‹é€²è¡Œçš„
    
    else:
        st.info("ğŸš€ **é–‹å§‹ä½¿ç”¨** - è«‹åœ¨å·¦å´ä¸Šå‚³æ‚¨çš„ Log æ–‡ä»¶é€²è¡Œåˆ†æ")
        
        st.markdown("""
        ### ğŸ“‹ æ”¯æ´çš„æª”æ¡ˆæ ¼å¼
        
        - **ğŸ® GPUMon CSV** - GPUæ€§èƒ½ç›£æ§æ•¸æ“šï¼ˆæº«åº¦ã€åŠŸè€—ã€é »ç‡ã€ä½¿ç”¨ç‡ï¼‰
        - **ğŸ–¥ï¸ PTAT CSV** - CPUæ€§èƒ½ç›£æ§æ•¸æ“šï¼ˆé »ç‡ã€åŠŸè€—ã€æº«åº¦ï¼‰
        - **ğŸ“Š YOKOGAWA Excel/CSV** - å¤šé€šé“æº«åº¦è¨˜éŒ„å„€æ•¸æ“š
        
        ### âœ¨ ä¸»è¦åŠŸèƒ½
        
        - **ğŸ“‹ æ™ºèƒ½è§£æ** - è‡ªå‹•è­˜åˆ¥ä¸åŒé¡å‹çš„Logæª”æ¡ˆæ ¼å¼
        - **ğŸ¯ å¤šæª”æ¡ˆåˆ†æ** - åŒæ™‚ä¸Šå‚³å¤šå€‹æª”æ¡ˆï¼Œæ¯å€‹æª”æ¡ˆç¨ç«‹åˆ†æ
        - **ğŸ“Š å³æ™‚äº’å‹•** - æ™‚é–“ç¯„åœå’Œåƒæ•¸èª¿æ•´å³æ™‚æ›´æ–°åœ–è¡¨
        - **ğŸ“‹ Summaryæ•´åˆ** - æ‰€æœ‰æº«åº¦æ•¸æ“šæ•´åˆæˆå¸¶é‚Šæ¡†HTMLè¡¨æ ¼
        - **ğŸ’¾ ä¸€éµè¤‡è£½** - HTMLè¡¨æ ¼å¯ç›´æ¥è¤‡è£½åˆ°Wordä¿ç•™æ ¼å¼
        
        ### ğŸ¯ ä½¿ç”¨æµç¨‹
        
        1. **ä¸Šå‚³æª”æ¡ˆ** - åœ¨å·¦å´é¸æ“‡ä¸€å€‹æˆ–å¤šå€‹Logæª”æ¡ˆ
        2. **æŸ¥çœ‹åˆ†æ** - æ¯å€‹æª”æ¡ˆéƒ½æœ‰å°ˆå±¬çš„æ¨™ç±¤é å’Œåœ–è¡¨æ§åˆ¶
        3. **æ•´åˆå ±å‘Š** - åœ¨Summaryæ¨™ç±¤é æŸ¥çœ‹æ‰€æœ‰æº«åº¦æ•¸æ“šæ•´åˆè¡¨æ ¼
        4. **è¤‡è£½ä½¿ç”¨** - ç›´æ¥è¤‡è£½HTMLè¡¨æ ¼åˆ°Wordæˆ–Excel
        """)


if __name__ == "__main__":
    main()
