# =============================================================================
# thermal_analysis_platform_v10.4.0_word_auto.py
# 2026 å¹´åº¦å‡ç´šç‰ˆï¼šæ•¸æ“šåˆ†æ + Word å ±å‘Šä¸€éµç”Ÿæˆ
# =============================================================================

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import io
import os
import json
from datetime import datetime, date, timedelta
from abc import ABC, abstractmethod
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from docxtpl import DocxTemplate  # <--- æ–°å¢ Word å¼•æ“

# ç‰ˆæœ¬è³‡è¨Š
VERSION = "v10.4.0 - Word Automation Ready"
VERSION_DATE = "2026å¹´1æœˆ"

# =============================================================================
# 1. æ ¸å¿ƒè‡ªå‹•åŒ–çµ„ä»¶ (æ–°å¢ï¼šWord å ±å‘Šå°èˆªå“¡)
# =============================================================================

class WordExporter:
    """è‡ªå‹•å¡«è¡¨æ©Ÿå™¨äººï¼šè² è²¬å°‡è¨ˆç®—å¥½çš„ summary å¡«å…¥ Word æ¨™ç±¤ä¸­"""
    
    @staticmethod
    def generate_report(summary_df: pd.DataFrame, template_bytes: io.BytesIO) -> io.BytesIO:
        """
        è‡ªå‹•å°æ¨™é‚è¼¯ï¼š
        å°‡ summary_df ä¸­çš„ 'Ch.' æ¬„ä½è½‰æ›ç‚º Word æ¨™ç±¤ã€‚
        ä¾‹å¦‚ï¼šCh. 1 çš„æ•¸æ“šæœƒå°æ‡‰åˆ° Word è£¡çš„ {{ch1_c1}}
        """
        # è¼‰å…¥ç¯„æœ¬
        doc = DocxTemplate(template_bytes)
        
        # æ§‹å»ºã€Œæ•¸æ“šåŒ…ã€ (Context)
        context = {
            "report_date": date.today().strftime("%Y-%m-%d"),
            "total_channels": len(summary_df)
        }
        
        # å‹•æ…‹å°æ‡‰æ¯å€‹é‡æ¸¬é»
        for _, row in summary_df.iterrows():
            ch_num = row['Ch.']
            temp_val = row['Result (Case Temp)']
            # å»ºç«‹å°æ‡‰é—œä¿‚ï¼Œå¦‚ ch1_c1, ch2_c1...
            context[f"ch{ch_num}_c1"] = temp_val
            # åŒæ™‚ä¹ŸæŠŠ Location å‚³é€²å»ï¼Œå¦‚æœ Word æœ‰éœ€è¦å¯ä»¥é¡¯ç¤º
            context[f"name{ch_num}"] = row['Location']
            
        # åŸ·è¡Œå¡«è‰²ï¼ˆæ¸²æŸ“ï¼‰
        doc.render(context)
        
        # å­˜å…¥è¨˜æ†¶é«”æµä¾›ä¸‹è¼‰
        output_stream = io.BytesIO()
        doc.save(output_stream)
        output_stream.seek(0)
        return output_stream

# =============================================================================
# 2. æ•¸æ“šæ¨¡å‹èˆ‡è§£æç³»çµ± (ä¿ç•™åŸæœ‰è§£æé‚è¼¯ä¸¦å„ªåŒ–)
# =============================================================================

@dataclass
class LogMetadata:
    filename: str
    log_type: str
    rows: int
    columns: int
    time_range: str
    file_size_kb: float

class LogData:
    def __init__(self, df: pd.DataFrame, metadata: LogMetadata):
        self.df = df
        self.metadata = metadata
        self._numeric_columns = df.select_dtypes(include=['number']).columns.tolist()

    def filter_by_time(self, x_limits: Tuple[float, float]):
        if x_limits is None: return self.df
        x_min_td = pd.to_timedelta(x_limits[0], unit='s')
        x_max_td = pd.to_timedelta(x_limits[1], unit='s')
        return self.df[(self.df.index >= x_min_td) & (self.df.index <= x_max_td)]

# (å…¶é¤˜è§£æå™¨ Parser é‚è¼¯èˆ‡ v10.3.8 ç›¸åŒï¼Œç‚ºç¯€çœç¯‡å¹…åœ¨æ­¤ç°¡åŒ–å‘ˆç¾ï¼Œ
# ä½†ä¿ç•™å®Œæ•´çš„ SummaryRenderer èˆ‡ UI å·¥å» é‚è¼¯)

# ... [æ­¤è™•çœç•¥åŸæœ‰ ParserRegistry, GPUMonParser, PTATParser å¯¦ä½œç´°ç¯€ï¼Œèˆ‡ä½ æä¾›çš„ v10.3.8 ä¸€è‡´] ...

# =============================================================================
# 3. UI å‘ˆç¾å±¤ (æ–°å¢ï¼šWord ä¸‹è¼‰æŒ‰éˆ•)
# =============================================================================

class SummaryRenderer:
    def __init__(self, log_data_list: List[LogData]):
        self.log_data_list = log_data_list

    def render(self):
        st.markdown("""
        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 1.5rem; border-radius: 10px; color: white;">
            <h3>ğŸ“‹ æº«åº¦æ•´åˆæ‘˜è¦ & Word å ±å‘Šç”¢å‡º</h3>
            <p>å·²æ•´åˆæ•¸æ“šï¼Œä¸¦è‡ªå‹•æº–å‚™å¥½ Word æ¨™ç±¤ï¼š{{ch1_c1}} ~ {{ch31_c1}}</p>
        </div>
        """, unsafe_allow_html=True)
        
        # 1. ç”Ÿæˆæ‘˜è¦è¡¨æ ¼
        # [æ­¤è™•èª¿ç”¨ TemperatureSummaryGenerator.generate_summary_table]
        from __main__ import TemperatureSummaryGenerator # ç¢ºä¿å¼•ç”¨åˆ°
        summary_df = TemperatureSummaryGenerator.generate_summary_table(self.log_data_list)
        
        if summary_df.empty:
            st.warning("è«‹å…ˆä¸Šå‚³æª”æ¡ˆä»¥ç”¢å‡ºæ‘˜è¦ã€‚")
            return

        # 2. é è¦½è¡¨æ ¼
        st.markdown("### ğŸ” æ•¸æ“šé è¦½")
        st.dataframe(summary_df, use_container_width=True)

        # 3. Word è‡ªå‹•åŒ–æŒ‰éˆ• (æ ¸å¿ƒæ–°å¢)
        st.markdown("---")
        st.markdown("### ğŸ“¥ ç”¢å‡ºæ­£å¼æ¸¬è©¦å ±å‘Š")
        st.info("ğŸ’¡ è«‹ç¢ºä¿æ‚¨çš„ Word ç¯„æœ¬ä¸­å·²åŸ‹å…¥ {{ch1_c1}} ç­‰æ¨™ç±¤ã€‚")
        
        uploaded_template = st.file_uploader("ğŸ“‚ ä¸Šå‚³æ‚¨çš„ Word ç¯„æœ¬ (.docx)", type=['docx'])
        
        if uploaded_template and st.button("ğŸš€ ç”Ÿæˆå ±å‘Šä¸¦ä¸‹è¼‰"):
            with st.spinner("æ­£åœ¨å°‡æ•¸æ“šå¡«å…¥ Word ç¯„æœ¬..."):
                try:
                    template_bytes = io.BytesIO(uploaded_template.read())
                    report_stream = WordExporter.generate_report(summary_df, template_bytes)
                    
                    st.download_button(
                        label="â¬‡ï¸ é»æ“Šä¸‹è¼‰ç”¢å‡ºçš„ Word å ±å‘Š",
                        data=report_stream,
                        file_name=f"Thermal_Test_Report_{date.today()}.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                    )
                    st.success("âœ… å ±å‘Šç”ŸæˆæˆåŠŸï¼æ•¸æ“šå·²æ ¹æ“š Ch. åºè™Ÿè‡ªå‹•å°æ‡‰ã€‚")
                except Exception as e:
                    st.error(f"âŒ ç”Ÿæˆå¤±æ•—ï¼š{e}")

# =============================================================================
# 4. çµ±è¨ˆèˆ‡è¼”åŠ©åŠŸèƒ½ (ä¿ç•™åŸæœ‰ Generator é‚è¼¯)
# =============================================================================

class TemperatureSummaryGenerator:
    @staticmethod
    def generate_summary_table(log_data_list: List[LogData]) -> pd.DataFrame:
        summary_data = []
        ch_num = 1
        for log in log_data_list:
            df = log.df
            numeric_cols = df.select_dtypes(include=['number']).columns
            temp_cols = [c for c in numeric_cols if c not in ['Date', 'sec', 'RT', 'TIME']]
            
            for col in temp_cols:
                max_v = df[col].max()
                clean_name = col.replace('YOKO: ', '').replace('PTAT: ', '').replace('GPU: ', '')
                summary_data.append({
                    'Ch.': ch_num,
                    'Location': clean_name,
                    'Result (Case Temp)': round(max_v, 1) if pd.notna(max_v) else "N/A"
                })
                ch_num += 1
        return pd.DataFrame(summary_data)

# =============================================================================
# 5. å•Ÿå‹•å…¥å£ (Main)
# =============================================================================

def main():
    # ... [åŸæœ‰é é¢è¨­å®šèˆ‡å´é‚Šæ¬„é‚è¼¯] ...
    # é€™è£¡æœƒè§¸ç™¼å„å€‹ Renderer çš„æ¸²æŸ“åŠŸèƒ½
    pass

if __name__ == "__main__":
    # åŸ·è¡Œä¸»ç¨‹å¼é‚è¼¯
    # (æ­¤è™•ç‚ºç¤ºæ„ï¼Œå»ºè­°å°‡æ­¤å®Œæ•´ Code èˆ‡ä½ åŸæœ‰çš„ v10.3.8 çµæ§‹åˆä½µ)
    st.title(f"ğŸš€ {VERSION}")
    # ... åŸæœ‰ä¸»æµç¨‹ ...
